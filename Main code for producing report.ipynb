{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b541ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import regex as re\n",
    "# for nlp tags\n",
    "import spacy\n",
    "\n",
    "#prevents warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# my functions\n",
    "import pscCatTypeComp as my\n",
    "which_sh = my.which_sh\n",
    "get_pos_tags = my.get_pos_tags\n",
    "assign_pos = my.assign_pos\n",
    "choose_sh = my.choose_sh\n",
    "consecutive = my.consecutive\n",
    "most_frequent = my.most_frequent\n",
    "jaccard_similarity = my.jaccard_similarity\n",
    "squared_sum = my.squared_sum\n",
    "cos_similarity = my.cos_similarity\n",
    "similarity_scoring = my.similarity_scoring\n",
    "psc_to_sh = my.psc_to_sh\n",
    "get_per_vals = my.get_per_vals\n",
    "search_sequence_numpy = my.search_sequence_numpy\n",
    "get_sh_from_shs = my.get_sh_from_shs\n",
    "is_psc = my.is_psc\n",
    "check_act = my.check_act\n",
    "get_controls = my.get_controls\n",
    "remove_space_list = my.remove_space_list\n",
    "check_old_names = my.check_old_names\n",
    "format_chips_op = my.format_chips_op\n",
    "merge_names_nat = my.merge_names_nat\n",
    "how_different = my.how_different\n",
    "entity_extract = my.entity_extract\n",
    "preprocess_df = my.preprocess_df\n",
    "tag_multiple = my.tag_multiple\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c792564",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Webservice backlog feb oct.csv\")\n",
    "\n",
    "# ACTION CODE LOAD\n",
    "df_act = pd.read_csv(\"Action Code.csv\",encoding = 'utf-8')\n",
    "df_act['ACTION_CODE_EFF_DATE'] = pd.to_datetime(df_act.ACTION_CODE_EFF_DATE)\n",
    "df_act = df_act.sort_values(by = 'ACTION_CODE_EFF_DATE',ascending = False)\n",
    "\n",
    "# NATIONALITY LOAD & PREPROCESS\n",
    "df_off = pd.read_csv(\"Officer Details.csv\")\n",
    "nationalities = list(df_off.OFFICER_NATIONALITY.apply(lambda x: x.lower() if type(x) == str else '').unique())\n",
    "nationalities.remove('')\n",
    "nationalities = [nat for nat in nationalities if ',' not in nat]\n",
    "\n",
    "\n",
    "df_nat_and_adj = pd.read_csv(\"Countries and Nationalities.csv\")\n",
    "\n",
    "# making all lower case\n",
    "for col in df_nat_and_adj.columns:\n",
    "    df_nat_and_adj[col] = df_nat_and_adj[col].apply(lambda x: x.lower())\n",
    "    \n",
    "nationalities = nationalities + [nat for nat in df_nat_and_adj.country.values if nat not in nationalities] + [nat for nat in df_nat_and_adj.adjectivals.values if nat not in nationalities]    \n",
    "nationalities = list(set(nationalities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a78401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_officers(df):\n",
    "    df['LB'] = df.DESCRIPTION.apply(lambda x: min([9999] + [int(item) for item in x.replace('%','').split(' ') if item.isdigit() == True]))\n",
    "    df['UB'] = df.DESCRIPTION.apply(lambda x: max([0] + [int(item) for item in x.replace('%','').split(' ') if item.isdigit() == True]))\n",
    "    df.loc[df.LB == 9999,'LB'] = np.nan\n",
    "    df.loc[df.UB == 0,'UB'] = np.nan\n",
    "    df.loc[(df.LB == 75) & (df.UB == 75),'UB'] = 100\n",
    "    df['TYPE'] = df.DESCRIPTION.apply(lambda x: 'NOC' if 'shares' in x else 'VR' if 'voting' in x else 'SIC')\n",
    "    df['AS'] = df.DESCRIPTION.apply(lambda x: 'trust' if 'trust' in x else 'person' if 'person' in x else 'firm')\n",
    "    \n",
    "    df['merged_name'] =  [merge_names_nat(x).replace('  ',' ') for x in df[['OFFICER_FORENAME_1','OFFICER_FORENAME_2','OFFICER_SURNAME']].values]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_off = preprocess_officers(df_off)\n",
    "df_off.sample(5).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e866251",
   "metadata": {},
   "source": [
    "# NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f482ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_extraction_get_df(psc_id,df_name,trace = False):\n",
    "    # first check action code...\n",
    "    cont_id = df_name[df_name.PSC_DISCREPANCY_ID == psc_id].CONTACT_ID.values[0]\n",
    "    \n",
    "    # fetching data we need to complete\n",
    "    row_df = df_name[df_name.PSC_DISCREPANCY_ID == psc_id]\n",
    "    txt = row_df.discrepancy_detail.values[0]\n",
    "    corp_id = row_df.CORPORATE_BODY_ID.values[0]\n",
    "    psc_name = row_df.extract_psc_name.values[0].lower()\n",
    "    \n",
    "    df_cont = df_off[df_off.CONTACT_ID == cont_id]\n",
    "    df_cont['merged_name'] = [merge_names_nat(x).replace('  ',' ') for x in df_cont[['OFFICER_FORENAME_1','OFFICER_FORENAME_2','OFFICER_SURNAME']].values]\n",
    "\n",
    "    sh_names = df_cont.merged_name.unique() #list(set(df_sh_names[df_sh_names['corp_id'] == corp_id].sh_names.values[0]))\n",
    "    sh_surnames = [name.split(' ')[-1].lower() for name in sh_names if type(name) == str ]\n",
    "\n",
    "    # using officer information to retrieve sh names\n",
    "    #off_names = \n",
    "    #print(\"OFFICERS : \",off_names)\n",
    "    \n",
    "    # now we have collected all our information we should set up the breakdown dataframe:\n",
    "    \n",
    "    # 1) Preprocessing...\n",
    "    txt_orig = txt\n",
    "    txt = txt.lower()\n",
    "    \n",
    "    remove_punc = ['.','/','? ','[',']',')','(','!','\"','£','$','%','^','&','*','\\n','\\r',',',';',\"'s \"] # ,' - '\n",
    "    remove_words = [' and ',' the ',' an ',' for ',' was ',' is ',' as ',' to ',' from ',' it ',' be ',' of ',' part ',' psc ',\n",
    "                    ' name ',' date ',' her ',' he ',' his ',' hers ',' their ',' theirs ',' him ',' she ',' this ',' them ',\n",
    "                    ' psc ',' director ',' they ',' there ',' individual ',' dob ','vs ',' ch ',' id ',' a ',' on ',' or ',\n",
    "                   ' in ']\n",
    "                   \n",
    "    txt = txt.replace(':',' : ')\n",
    "    # removals of chars we dont want:\n",
    "    for punc in remove_punc:\n",
    "        txt = txt.replace(punc,' ')\n",
    "    for word in remove_words:\n",
    "        txt = txt.replace(word,' ')\n",
    "        txt = txt.replace(word[:-1]+'-',' ') # replaces things like \"name-\" rather than just \" name \"\n",
    "        \n",
    "    txt = txt.replace('-',' - ') # for doubel barrel surnames so we can match easier, these will be rejoined later on\n",
    "    txt = txt.replace(\"' \",' ').replace(\" '\",' ').replace('?','')\n",
    "\n",
    "    # splitting and removal of blank chars\n",
    "    txt_split = txt.split(' ')\n",
    "    \n",
    "    while '' in txt_split:\n",
    "        txt_split.remove('')\n",
    "    \n",
    "    # o/p for testing phase\n",
    "    if trace == True:\n",
    "        print(\"==========================================================================================================\")\n",
    "        print(\"PSC_ID : \"+str(psc_id))\n",
    "        print(\"CORP ID : \"+str(corp_id))\n",
    "        print(\"CONT ID :\"+str(cont_id))\n",
    "        print(\"PSC Name Given : \"+psc_name)\n",
    "        print(\"Shareholders : \")\n",
    "        print(sh_names)\n",
    "        print(\"\\n<-----The text----->\\n\"+txt_orig)\n",
    "    \n",
    "    \n",
    "    # 2) Split into df then tagging\n",
    "    \n",
    "    # tagging set up\n",
    "    first_tags = ['1st','forename','first','middle','title']\n",
    "    second_tags = ['2nd','surname','last','double','barrel','married','maiden']\n",
    "    title_tags = ['dr','mr','mrs','ms','mz']\n",
    "    negatives = ['isnt','not','remove','wrong']\n",
    "    \n",
    "    # checking if talking about married\n",
    "    married_markers = ['married','marriage','maiden']\n",
    "    married_test = False\n",
    "    for marker in married_markers:\n",
    "        if marker in txt_split:\n",
    "            married_test = True\n",
    "            \n",
    "            \n",
    "    # getting tags\n",
    "    tags = ['First' if x in first_tags else 'Second' if x in second_tags else 'Negative' if x in negatives else 'Title' if x in title_tags else 'JOIN' if x == '-' else 'JOIN_SPECIAL' if x in [':',';'] else np.nan for x in txt_split]\n",
    "    \n",
    "    # getting counts of first and second tag occurances...\n",
    "    first_count = tags.count('First')\n",
    "    second_count = tags.count('Second')\n",
    "    \n",
    "    \n",
    "    # checking if any obvious sh matches in txt\n",
    "    associated_sh = [which_sh(x,sh_names,psc_name) for x in txt_split]\n",
    "    \n",
    "    # creating df\n",
    "    df_txt = pd.DataFrame({'word':txt_split,'tags':tags,'associated_sh':associated_sh})\n",
    "    \n",
    "    # we also want to add spacy name ent tags to identify areas where name might mismatch...\n",
    "    pos_tags = get_pos_tags(txt_orig,nlp,reduce_ents = True)\n",
    "    pos_in_txt = [assign_pos(pos_tags,x) for x in txt_split]\n",
    "    df_txt['pos'] = pos_in_txt\n",
    "    df_txt['pos'][~df_txt.associated_sh.isna()] = 'PERSON'\n",
    "    \n",
    "    df_txt.loc[df_txt.pos.isna(),'pos'] = df_txt.loc[df_txt.pos.isna(),'word'].apply(lambda x: 'PERSON' if (x in ' '.join(sh_names) and x != '-') else np.nan)\n",
    "    \n",
    "    # we want to check the JOIN and see if names are either side for double barrels\n",
    "    inds_join = df_txt[df_txt.tags == 'JOIN'].index\n",
    "    join_names_inds = []\n",
    "    for ind in inds_join:\n",
    "        lower = ind-1 if ind-1 >= 0 else ind\n",
    "        \n",
    "        surrounding = df_txt.pos.iloc[[ind-1,ind,ind+1]] if ind-1 >= 0 else df_txt.pos.iloc[[ind,ind+1]] # gets surrounding pos tags\n",
    "        if 'PERSON' in surrounding.values: # checks if person is being spoken about\n",
    "            if ind -1 >= 0:\n",
    "                df_txt.loc[[ind-1,ind,ind+1],'pos'] = 'PERSON' # assigns person tag to join\n",
    "            else:\n",
    "                df_txt.loc[[ind,ind+1],'pos'] = 'PERSON'\n",
    "            join_names_inds.append(ind)\n",
    "     \n",
    "    # below checked for tag situation of \"PERSON nan PERSON\" and we assume the sandwiched nan is also PERSON or part-of-name\n",
    "    inds_to_tag = []\n",
    "    for ind in df_txt.index[2:]:\n",
    "        if (df_txt.loc[ind,'pos'] == 'PERSON') and (df_txt.loc[ind-2,'pos'] == 'PERSON'):\n",
    "            inds_to_tag.append(ind-1)\n",
    "    \n",
    "    df_txt.loc[inds_to_tag,'pos'] = 'PERSON'\n",
    "    \n",
    "    # creating matched column\n",
    "    df_txt['matched'] = False\n",
    "    df_txt['matched'][(~df_txt.associated_sh.isna()) & (df_txt.pos == 'PERSON') ] = True\n",
    "    df_txt['matched'][df_txt.tags == 'JOIN'] = True\n",
    "    \n",
    "    if df_txt.shape[0] >=2:\n",
    "        if df_txt.pos.values[-2] == 'PERSON':\n",
    "            df_txt.loc[df_txt.shape[0]-1,'pos'] = 'PERSON'\n",
    "        \n",
    "    df_txt.loc[df_txt[df_txt.tags == 'Negative'].index,'pos'] = np.nan    \n",
    "    \n",
    "    # searching for surname: or surname - tags, same for forename\n",
    "    drop_point = []\n",
    "    for i in range(0,df_txt.shape[0]):\n",
    "        tag = df_txt.loc[i,'tags']\n",
    "        if (tag in ['First','Second']) and ( i < df_txt.shape[0]-1):\n",
    "            if (df_txt.loc[i+1,'tags'] == 'JOIN_SPECIAL'):\n",
    "                df_txt.loc[i+2,'pos'] = 'PERSON'\n",
    "                drop_point.append(i+1)\n",
    "                drop_point.append(i)\n",
    "    \n",
    "    df_txt = df_txt.drop(drop_point)\n",
    "    df_txt.reset_index(drop = True,inplace = True)\n",
    "    \n",
    "    df_txt['associated_sh'] = df_txt['associated_sh'].apply(lambda x: choose_sh(x,psc_name))\n",
    "    \n",
    "    # additional name capture element\n",
    "    person_inds = list(df_txt[df_txt.pos == 'PERSON'].index)\n",
    "    for ind in person_inds:\n",
    "        current = df_txt.loc[ind,'word']\n",
    "        current = current[0].upper() + current[1:]\n",
    "        \n",
    "        if ind-1 >= df_txt.index[0]:\n",
    "            consider_before = df_txt.loc[ind-1,'word']\n",
    "            \n",
    "            if ((consider_before[0] < 'a' or consider_before[0] > 'z')):\n",
    "                continue\n",
    "                \n",
    "            consider_before = consider_before[0].upper() + consider_before[1:]\n",
    "            \n",
    "            if ' '.join([consider_before,current]) in txt_orig:\n",
    "                df_txt.loc[ind-1,'pos'] = 'PERSON'\n",
    "            \n",
    "        if ind+1 <= df_txt.index[-1]:\n",
    "            consider_after = df_txt.loc[ind+1,'word']\n",
    "            \n",
    "            if ((consider_after[0] < 'a' or consider_after[0] > 'z')):\n",
    "                continue\n",
    "            \n",
    "            consider_after = consider_after[0].upper() + consider_after[1:]\n",
    "            \n",
    "            if current + ' ' +consider_after in txt_orig:\n",
    "                df_txt.loc[ind+1,'pos'] = 'PERSON'\n",
    "        \n",
    "    \n",
    "    \n",
    "    # need a final check for consecutive sh where difference in names, we will take first as assumed subject\n",
    "    inds_peoples = df_txt[~df_txt.associated_sh.isna()].index\n",
    "    if len(inds_peoples) > 1:\n",
    "        prev_ind = inds_peoples[0]\n",
    "        for i in range(1,len(inds_peoples)):\n",
    "            ind = inds_peoples[i]\n",
    "            if ind-1 == prev_ind:\n",
    "                df_txt.loc[ind,'associated_sh'] = df_txt.loc[ind-1,'associated_sh']\n",
    "\n",
    "            prev_ind = ind\n",
    "            \n",
    "    noc_buzzwords = ['nature of control','ownership','shares','voting']           \n",
    "    noc_found = any([True if x in txt else False for x in noc_buzzwords]) == True\n",
    "\n",
    "    return df_txt, psc_name, sh_names, married_test, [first_count,second_count],noc_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec50a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_of_issue(psc_id,df_txt,psc_name,sh_names,married,counts,noc_found,trace = False):\n",
    "    \n",
    "    cont_id = df[df.PSC_DISCREPANCY_ID == psc_id].CONTACT_ID.values[0]\n",
    "    \n",
    "    txt_split = df_txt['word'].values.tolist()\n",
    "    sh_surnames = [name.split(' ')[-1].lower() for name in sh_names if type(name) == str ]\n",
    "    \n",
    "    # extract the areas where PERSON sequence is in pos but not all matched\n",
    "    inds_person = list(df_txt[df_txt.pos == 'PERSON'].index)\n",
    "    inds_groups = consecutive(inds_person)\n",
    "    if len(inds_person) > 0:\n",
    "        for i in range(0,len(inds_groups)):\n",
    "            group = inds_groups[i]\n",
    "            \n",
    "            # checking group hasnt captured two consecutive\n",
    "            group_name = list(df_txt.loc[group,'word'].values)\n",
    "            first_name = group_name[0]\n",
    "            if first_name in group_name[1:]: # checks if name is later part of group\n",
    "                ind_to_split = group_name[1:].index(first_name) + 1\n",
    "                first_group = group[:ind_to_split]\n",
    "                second_group = group[ind_to_split:]\n",
    "\n",
    "                del inds_groups[i]\n",
    "                inds_groups.append(first_group)\n",
    "                inds_groups.append(second_group)\n",
    "        \n",
    "    # going through groups and only  keep those where not all are matched\n",
    "    unmatched_groups = [] \n",
    "\n",
    "    for group in inds_groups:\n",
    "        current_name = ' '.join(df_txt.loc[group,'word']).replace(' - ','-')\n",
    "\n",
    "        if (current_name != psc_name) and (current_name not in sh_names) : # checks if all matched\n",
    "            unmatched_groups.append(group)\n",
    "     \n",
    "    # want to see groups so will convert to text\n",
    "    group_words = []\n",
    "    for group in inds_groups:\n",
    "        name = ' '.join(df_txt.loc[group,'word']).replace(' - ','-')\n",
    "        group_words.append(name)\n",
    "        \n",
    "    while '' in group_words:\n",
    "        group_words.remove('')\n",
    "    \n",
    "    # we want to remove titles from groups\n",
    "    titles = ['dr','mr','mrs','mx','ms','miss','master','sir','lord']\n",
    "    for i in range(len(group_words)):\n",
    "        group = group_words[i]\n",
    "        for item in titles:\n",
    "            if item in group.split(' '):\n",
    "                group_split = group.split(' ')\n",
    "                group_split.remove(item)\n",
    "                group_words[i] = ' '.join(group_split)\n",
    "            \n",
    "    # When no groups are found :\n",
    "    if len(group_words) == 0:\n",
    "        if counts[1] > 0: #surname mentioned\n",
    "            if married == True: # check if about marriage\n",
    "                return ['MARRIAGE - LOW',[psc_name],['Error: see discrepancy details']]\n",
    "            else:\n",
    "                return ['SURNAME - HIGH',[psc_name],['Error: see discrepancy details']]\n",
    "            \n",
    "        elif counts[0] > 0: # forename mentioned surname not\n",
    "            return ['FORENAME - NONE',[psc_name],['Error: see discrepancy details']]\n",
    "        \n",
    "        else: # no mention of either\n",
    "            if married == True: # check if about marriage\n",
    "                return ['MARRIAGE - LOW',[psc_name],['Error: see discrepancy details']]\n",
    "            else:\n",
    "                return ['COULD NOT DETERMINE - HIGH',[psc_name],['Error: see discrepancy details']]\n",
    "            \n",
    "    \n",
    "    removal_words = ['forename','first name','second name','middle name','surname','maiden','married','should',]\n",
    "    unmatched_words = []\n",
    "    for group in unmatched_groups:\n",
    "        name = ' '.join(df_txt.loc[group,'word']).replace(' - ','-')\n",
    "        for rem in removal_words:\n",
    "            name = name.replace(rem,'')\n",
    "        unmatched_words.append(name)\n",
    "    \n",
    "    \n",
    "    unmatched_words = list(set(unmatched_words))\n",
    "    #print(unmatched_words)\n",
    "    # we want to remove titles from groups\n",
    "    titles = ['dr','mr','mrs','mx','ms','miss','master','sir','lord']\n",
    "    for i in range(len(unmatched_words)):\n",
    "        group = unmatched_words[i]\n",
    "        for item in titles:\n",
    "            if item in group.split(' '):\n",
    "                group_split = group.split(' ')\n",
    "                group_split.remove(item)\n",
    "                unmatched_words[i] = ' '.join(group_split)\n",
    "    \n",
    "    \n",
    "    # checking if shs_in_txt if multiple officers...\n",
    "    df_sliced = df_off[df_off.CONTACT_ID == cont_id] # gets relevant officers info\n",
    "    \n",
    "    if psc_name != 'psc missing':\n",
    "        sh_names = psc_to_sh(df_sliced.merged_name.unique(),psc_name)\n",
    "    \n",
    "    for name in unmatched_words:\n",
    "        if name == sh_names:\n",
    "            print(name)\n",
    "            unmatched_words.remove(name)\n",
    "\n",
    "    # removing empties\n",
    "    while '' in group_words:\n",
    "        group_words.remove('')\n",
    "    while '' in unmatched_words:\n",
    "        unmatched_words.remove('')\n",
    "    \n",
    "    \n",
    "    \n",
    "    if trace == True:\n",
    "        print(\"\\nGroups: \")\n",
    "        print(group_words)\n",
    "        print(\"\\nUnmatched :\")\n",
    "        print(unmatched_words)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    shs_in_txt = df_txt.associated_sh.values if psc_name == 'psc missing' else [sh_names]\n",
    "    shs_split = []\n",
    "    for sh in shs_in_txt:\n",
    "        if type(sh) == str:\n",
    "            if '/' in sh:\n",
    "                for s in sh.split('/'):\n",
    "                    if s not in shs_split:\n",
    "                        shs_split.append(s)\n",
    "                continue\n",
    "            if sh not in shs_split:\n",
    "                shs_split.append(sh)\n",
    "        \n",
    "    shs_in_txt = shs_split # this will hold all share holders found in text, any undecided are split and both added\n",
    "    differences = [] # stores difference per unmatched item\n",
    "    \n",
    "    officer_names = list(df_sliced.merged_name.unique())\n",
    "    officer_ids = df_sliced[df_sliced.merged_name == psc_to_sh(officer_names,psc_name)].OFFICER_ID.unique()\n",
    "\n",
    "    if trace == True:\n",
    "        print(\"OFFICER NAMES : \",officer_names)\n",
    "        print(\"OFFICER IDS : \",officer_ids)\n",
    "        print(\"REMAINING UNMATCHED : \",unmatched_words)\n",
    "    \n",
    "    # CHECKS FOR MULTIPLE IDS OR NAMES UNDER SINGLE PERSON\n",
    "    if len(officer_ids) == 1: # if one found we need to check if many names are listed\n",
    "        if df_sliced[df_sliced.OFFICER_ID == officer_ids[0]].shape[0] > 1:\n",
    "            off_names = list(df_sliced[df_sliced.OFFICER_ID == officer_ids[0]].merged_name.unique())\n",
    "            off_surs = list(set([name.split(' ')[-1] for name in off_names]))\n",
    "            if len(off_surs) > 1:\n",
    "                return ['MULTIPLE ENTRIES FOR ID SURNAME - HIGH',off_names,unmatched_words]\n",
    "            elif len(off_names) > 1:\n",
    "                return ['MULTIPLE ENTRIES FOR ID FORENAME - LOW',off_names,unmatched_words]\n",
    "\n",
    "            \n",
    "    elif len(officer_ids) < len(shs_in_txt):\n",
    "        off_names = list(df_sliced[df_sliced.OFFICER_ID == officer_ids[0]].merged_name.unique())\n",
    "        off_surs = list(set([name.split(' ')[-1] for name in off_names]))\n",
    "        if len(off_surs) > 1:\n",
    "            return ['MULTIPLE ENTRIES FOR ID SURNAME - HIGH',off_names,unmatched_words]\n",
    "        elif len(off_names) > 1:\n",
    "            return ['MULTIPLE ENTRIES FOR ID FORENAME - LOW',off_names,unmatched_words]    \n",
    "        \n",
    "    # CHECKING REMAINING UNMATCHED\n",
    "    if psc_name.lower() == 'psc missing':\n",
    "        psc_name = most_frequent(shs_in_txt)\n",
    "    \n",
    "    our_sh = psc_to_sh(officer_names,psc_name) # gets sh name associated with psc\n",
    "    our_sur = our_sh.split(' ')[-1]\n",
    "    our_fore = our_sh.split(' ')[:-1]\n",
    "    differences = []\n",
    "    if len(unmatched_words) > 0:\n",
    "        for unmatched in unmatched_words:\n",
    "            if unmatched == our_sh.lower():\n",
    "                continue\n",
    "            if len(unmatched.split(' ')) == 1: # if only one name in unmatched\n",
    "                if (unmatched in our_fore) or (unmatched == our_sur):\n",
    "                    differences.append(\"ALL MATCHED - LOW\")\n",
    "                elif counts[1] > 0:\n",
    "                    differences.append(\"SURNAME - HIGH\" if how_different(unmatched,our_sur) > 2 else 'SURNAME - MEDIUM')\n",
    "                else:\n",
    "                    differences.append(\"FORENAME - NONE\")\n",
    "                    \n",
    "            elif len(unmatched.split(' ')) > 1: # the case where current item is larger than 1\n",
    "                \n",
    "                unmatched_sur = unmatched.split(' ')[-1]\n",
    "                unmatched_fore = unmatched.split(' ')[:-1]\n",
    "                \n",
    "                if unmatched_sur != our_sur: # if surname doesnt match\n",
    "                    differences.append('SURNAME - HIGH' if how_different(unmatched,our_sur) > 2 else 'SURNAME - MEDIUM')\n",
    "                    \n",
    "                elif unmatched_fore != our_fore: # if surname does match\n",
    "                    differences.append('FORENAME - NONE')\n",
    "                    \n",
    "                else:\n",
    "                    continue # if all matched move on\n",
    "    else:\n",
    "        differences.append(\"ALL MATCHED - NONE\")\n",
    "        \n",
    "    priorities_ranked = ['SURNAME - HIGH','SURNAME - MEDIUM','FORENAME - NONE']\n",
    "    priority_assigned = 'ALL MATCHED - NONE'\n",
    "    \n",
    "    for prio in priorities_ranked: # getting highest priority\n",
    "        if prio in differences:\n",
    "            priority_assigned = prio\n",
    "            break\n",
    "            \n",
    "    if noc_found == True: # checking if NOC has been mentioned as this is common and should be HIGH\n",
    "        return ['NOC MENTIONED - HIGH',shs_in_txt,unmatched_words]\n",
    "    \n",
    "    if (priority_assigned in priorities_ranked[:2]) and (married == True): # checks if discrepancy is about marriage only if a higher priority is currently assigned\n",
    "        priority_assigned = 'MARRIAGE - LOW'\n",
    "        \n",
    "    if priority_assigned == 'ALL MATCHED - NONE':\n",
    "        unmatched_words = group_words\n",
    "        shs_in_txt = [sh_names] if type(sh_names) != list else sh_names\n",
    "        \n",
    "    return [priority_assigned,shs_in_txt,unmatched_words] # returns out priority, shareholders in text, and unmatched items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d152ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_prio(psc_id,df):\n",
    "    print(\"CURRENT ID : \",psc_id)\n",
    "    df_txt, psc_name, sh_names, married_test, counts,noc = name_extraction_get_df(psc_id,df,trace = False)\n",
    "    op = type_of_issue(psc_id,df_txt,psc_name,sh_names,married_test,counts,noc,trace = False)\n",
    "    # Assigning op to columns\n",
    "    index = df[df.PSC_DISCREPANCY_ID == psc_id].index[0]\n",
    "    df.loc[index,'priority_explained'] = op[0].split(' - ')[0] \n",
    "    df.loc[index,'priority'] = op[0].split(' - ')[1]\n",
    "    df.loc[index,'CHIPS_value'] = ' | '.join(op[1])\n",
    "    df.loc[index,'material_nonmaterial'] = 'MATERIAL' if ' NONE' not in op[0] else 'NON-MATERIAL'\n",
    "    to_return = ' | '.join(op[2]) \n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f2c2da",
   "metadata": {},
   "source": [
    "# NOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cd90fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_breakdown(df,psc_id):\n",
    "    # This function will return a dataframe which contains a breakdown of descrip_detail and tags per word\n",
    "    # This allows for easier decision making\n",
    "    \n",
    "    # => Getting Text and Shareholders <=\n",
    "    txt = df[df.PSC_DISCREPANCY_ID == psc_id].discrepancy_detail.iloc[0]\n",
    "    print(\"TEXT : \",txt)\n",
    "    comp_num = df[df.PSC_DISCREPANCY_ID == psc_id].COMPANY_NUMBER.iloc[0]\n",
    "    corp_id = df[df.PSC_DISCREPANCY_ID == psc_id].CORPORATE_BODY_ID.iloc[0]\n",
    "    psc_name = df[df.PSC_DISCREPANCY_ID == psc_id].extract_psc_name.iloc[0]\n",
    "    \n",
    "    df_sh = df_off[df_off.CORPORATE_BODY_ID == corp_id]\n",
    "    df_sh['merged_name'] = [merge_names_nat(x).replace('  ',' ') for x in df_sh[['OFFICER_FORENAME_1','OFFICER_FORENAME_2','OFFICER_SURNAME']].values]\n",
    "    shs = df_sh['merged_name'].unique()\n",
    "\n",
    "    # => PREPROCESSING AND POS TAGGING <=\n",
    "    pos_tags = get_pos_tags(txt,nlp,reduce_ents = True)\n",
    "    \n",
    "    # preprocessing\n",
    "    txt = txt.lower()\n",
    "    \n",
    "    if '  ' in txt:\n",
    "        txt.replace('  ',' ')\n",
    "    \n",
    "    \n",
    "    stop_words = ['.','!','\\n','\\r','>','<'] # these will be changed to have a space either side\n",
    "    extra_chars = [',','?','\"',':',';','£','$','^','&','*','(',')','_','/','-',\"'\",' fca '] # these are removed\n",
    "    \n",
    "    for stop in stop_words:\n",
    "        txt = txt.replace(stop, ' '+stop+' ') # replacing stop words\n",
    "    for ext in extra_chars:\n",
    "        txt = txt.replace(ext,' ') # removing extra chars\n",
    "    \n",
    "    txt = txt.replace('%','% ')\n",
    "    txt_split = txt.split(' ') # splits text word by word\n",
    "\n",
    "    while '' in txt_split:\n",
    "        txt_split.remove('') # removes extra blank spaces in split as we do not care for these\n",
    "        \n",
    "\n",
    "    # creating tags for each type...\n",
    "    shares = ['shares','share','sh','class','shareholding','shareholder','holding','owns','owner','holds','own','shared','shareholdings']\n",
    "    voting = ['vote','voting','rights']\n",
    "    sic = ['right','sic','significant','noc','appoint','directors','influence','control']\n",
    "    \n",
    "    type_tag = []\n",
    "    for word in txt_split:\n",
    "        if word in stop_words:\n",
    "            type_tag.append('STOP')\n",
    "            continue\n",
    "        elif word in shares:\n",
    "            type_tag.append('OWNERSHIP')\n",
    "            continue\n",
    "        elif word in sic:\n",
    "            type_tag.append('SIC')\n",
    "            continue\n",
    "        elif word in voting:\n",
    "            type_tag.append('VOTING')\n",
    "            continue\n",
    "        elif word in ['not','remove','false','wrong','incorrect','no','removed']:\n",
    "            type_tag.append('NEGATIVE')\n",
    "            continue\n",
    "        elif word in ['more','greater','>','over']:\n",
    "            type_tag.append('GREATER')\n",
    "            continue \n",
    "        elif word in ['less','<','under']:\n",
    "            type_tag.append('LESSER')\n",
    "            continue \n",
    "        elif (word == 'and') or (word == '&'):\n",
    "            type_tag.append('JOIN')\n",
    "            continue\n",
    "        elif word == 'ownership':\n",
    "            type_tag.append('SH/VOTE')\n",
    "            continue \n",
    "        type_tag.append(np.nan)\n",
    "    # ---> end of loop <---\n",
    "    \n",
    "    df_res = pd.DataFrame(columns = ['word','pos','type_tag','sh_name','per_value']) # sets up columns in df\n",
    "    # we need to ensure non key words aren't tagged so we add a boolean array to apply to\n",
    "    ignor_common = ['on','the','in','of','and','companies','house','than']\n",
    "    ignor_bool = [True if word not in ignor_common else False for word in txt_split]\n",
    "    \n",
    "    \n",
    "    df_res['word'] = txt_split # assigns text split to words\n",
    "    df_res['type_tag'] = type_tag\n",
    "    df_res['pos'][ignor_bool] = df_res.word[ignor_bool].apply(lambda x: assign_pos(pos_tags,x)) # gets tags per word\n",
    "    df_res['sh_name'][ignor_bool] = df_res.word[ignor_bool].apply(lambda x: which_sh(x,shs,psc_name))\n",
    "    df_res['sh_name'] = df_res.sh_name.fillna(value = np.nan)\n",
    "    df_res['per_value'] = df_res.word.apply(get_per_vals)\n",
    "\n",
    "    # the percentage column is taking 70.50% as 70.0 and 50.0%, we need to have the intelligence to \n",
    "    inds_per_val = df_res[~df_res.per_value.isna()].index\n",
    "    for i in range(1,len(inds_per_val)):\n",
    "        current_ind = inds_per_val[i]\n",
    "        prev_ind = inds_per_val[i-1]\n",
    "        if prev_ind == current_ind-2:\n",
    "            if df_res.word.loc[current_ind - 1] == '.':\n",
    "                combined_per = str(df_res.per_value.loc[prev_ind]).split('.')[0]+'.'+str(df_res.per_value.loc[current_ind]).split('.')[0]\n",
    "                df_res.per_value.loc[prev_ind] = np.nan\n",
    "                df_res.per_value.loc[current_ind] = float(combined_per)\n",
    "    \n",
    "    # when it is indicisive of who the name belongs to we can use surrounding names to know\n",
    "    # first we need th indicies where two or more names have been linked\n",
    "    non_nan_names = df_res[~df_res.sh_name.isna()]\n",
    "    bool_multi_names = [True if '/' in x else False for x in non_nan_names.sh_name.values]\n",
    "    inds_multi_names = non_nan_names[bool_multi_names].index # gets indices where mutliple are found\n",
    "    \n",
    "    for ind in inds_multi_names:\n",
    "        surrounding_names = df_res.sh_name.iloc[ind-1:ind+1].values\n",
    "        all_names = []\n",
    "        for item in surrounding_names: # if the name could not be determined we split and consider both\n",
    "            if type(item) == str:\n",
    "                if '/' in item:\n",
    "                    item_split = item.split('/')\n",
    "                    for part in item_split:\n",
    "                        all_names.append(part)\n",
    "                else:\n",
    "                    all_names.append(item) # if name was decded then append\n",
    "        \n",
    "        # now we want to find the most common\n",
    "        all_name_counts = [0 for i in range(len(all_names))] # found counts to be appended to\n",
    "        \n",
    "        for name in all_names: # goes through all found names incl. duplicates for count purposes\n",
    "            all_name_counts[int(all_names.index(name))] += 1 # adds 1 to count of name where name is found\n",
    "        \n",
    "        df_res.sh_name.iloc[ind] = all_names[all_name_counts == max(all_name_counts)] # appends data to have decided best name \n",
    "    \n",
    "    # merging pos and type_tag\n",
    "    df_res.type_tag[df_res.type_tag.isna()] = df_res[df_res.type_tag.isna()].pos\n",
    "    df_res.type_tag[~df_res.per_value.isna()] = 'DIGIT'\n",
    "    df_res.type_tag[~df_res.sh_name.isna()] = df_res[~df_res.sh_name.isna()].pos\n",
    "    \n",
    "    # assigning NAME tag to location with name match\n",
    "    #df_res.pos[~df_res.sh_name.isna()] = 'NAME'\n",
    "    \n",
    "    df_res.type_tag[(df_res.type_tag.isna()) & (~df_res.sh_name.isna())] = 'PERSON'\n",
    "    \n",
    "    df_res = df_res[['word','type_tag','sh_name','per_value']]\n",
    "    df_res['is_digit'] = df_res.type_tag.apply(lambda x: True if type(x) != str else False)\n",
    "    \n",
    "    df_res = df_res[~df_res.type_tag.isna()]\n",
    "    df_res.sh_name[df_res.sh_name == 'PERSON'] = str(psc_name).lower()\n",
    "    df_res = df_res.reset_index(drop = True)\n",
    "    \n",
    "    # checking dates havent been captured as digit\n",
    "    inds_digit = df_res[df_res.type_tag == 'DIGIT'].index.values\n",
    "    for i in range(0,len(inds_digit)):\n",
    "        ind = inds_digit[i]\n",
    "        if i >= 1:\n",
    "            if (df_res.loc[ind-1,'type_tag'] == 'DATE') or (df_res.loc[ind+1,'type_tag'] == 'DATE'):\n",
    "                df_res.loc[ind,'type_tag'] = 'DATE'\n",
    "                df_res.loc[ind,'per_value'] = np.nan\n",
    "        else:\n",
    "            if (df_res.loc[ind+1,'type_tag'] == 'DATE'):\n",
    "                df_res.loc[ind,'type_tag'] = 'DATE'\n",
    "                df_res.loc[ind,'per_value'] = np.nan\n",
    "    \n",
    "    # dealing with names that aren't full captured\n",
    "    inds_found = df_res[~df_res.sh_name.isna()].index.values\n",
    "    \n",
    "    if len(inds_found) > 0:\n",
    "        for ind in inds_found:\n",
    "            # forward propagation\n",
    "            current_tag = 'PERSON'\n",
    "            ind_new = ind + 1\n",
    "            while (current_tag == 'PERSON') and (ind_new < df_res.shape[0]):\n",
    "                current_tag = df_res.loc[ind_new,'type_tag']\n",
    "                if  current_tag == 'PERSON':\n",
    "                    df_res.loc[ind_new,'sh_name'] = df_res.loc[ind,'sh_name']\n",
    "                \n",
    "                ind_new += 1\n",
    "            \n",
    "            # backward propagation\n",
    "            current_tag = 'PERSON'\n",
    "            ind_new = ind -1\n",
    "            while (current_tag == 'PERSON') and (ind_new >= 0):\n",
    "                current_tag = df_res.loc[ind_new,'type_tag']\n",
    "                if current_tag == 'PERSON':\n",
    "                    df_res.loc[ind_new,'sh_name'] = df_res.loc[ind,'sh_name']\n",
    "                \n",
    "                ind_new -= 1\n",
    "                \n",
    "    # finally we want to get names into the sh_name column where an sh has not been identified but its a different individual\n",
    "    ind_ppl = df_res[(df_res.type_tag == 'PERSON') & (df_res.sh_name.isna())].index.values\n",
    "    \n",
    "    if len(ind_ppl) > 1:\n",
    "        groups_ppl = []\n",
    "        current_group = [ind_ppl[0]]\n",
    "\n",
    "        for i in range(1,len(ind_ppl)): # creating groups\n",
    "            if ind_ppl[i]-1 == ind_ppl[i-1]:\n",
    "                current_group.append(ind_ppl[i])\n",
    "            else:\n",
    "                groups_ppl.append(current_group)\n",
    "                current_group = [ind_ppl[i]]\n",
    "\n",
    "        groups_ppl.append(current_group)\n",
    "\n",
    "        for group in groups_ppl: # setting names\n",
    "            name = ' '.join(df_res.loc[group,'word'].values)\n",
    "            df_res.loc[group,'sh_name'] = name\n",
    "\n",
    "    elif len(ind_ppl) == 1:\n",
    "        df_res.loc[ind_ppl,'sh_name'] = df_res.loc[ind_ppl,'sh_name']\n",
    "    \n",
    "    df_res.loc[~df_res.sh_name.isna(),'sh_name']= df_res.loc[~df_res.sh_name.isna(),'sh_name'].apply(lambda x:is_psc(x,psc_name))\n",
    "    \n",
    "    # removal of psc check\n",
    "    removal_psc_tags = [\n",
    "        'removed from the psc','remove from the psc','remove psc','no longer psc','no longer a psc','psc to be removed', 'remove psc'\n",
    "    ]\n",
    "    remove = False\n",
    "    for tag in removal_psc_tags:\n",
    "        if tag in txt:\n",
    "            remove = True\n",
    "    #print(txt)\n",
    "    \n",
    "    # checking for limited by guarantee\n",
    "    limited_by = True if ('limited by guarantee' in txt) or ('ltd by guarantee' in txt) or ('no share company' in txt) or ('company has no shares' in txt) else False\n",
    "\n",
    "    return df_res, psc_name, remove,limited_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78aaff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakdown_to_op(psc_id,df_bd,df,psc_name,rem_tag,limited_tag):\n",
    "    # checking action codees\n",
    "    cont_id = df[df.PSC_DISCREPANCY_ID == psc_id].CONTACT_ID.iloc[0]\n",
    "    \n",
    "    # data fetching\n",
    "    \n",
    "    psc_name = psc_name.lower() if type(psc_name) == str else df[df.PSC_DISCREPANCY_ID == psc_id].extracted_name.values[0]\n",
    "    if psc_name != '':   \n",
    "        while psc_name[0] == ' ':\n",
    "            psc_name = psc_name[1:]\n",
    "    \n",
    "    # checking if removal of psc\n",
    "    if rem_tag == True:\n",
    "        return ['REMOVAL - HIGH',psc_name,psc_name], df_bd\n",
    "    \n",
    "    # Extracting SH in text and determining if multiple found\n",
    "    sh_in_txt = df_bd[~df_bd.sh_name.isna()].sh_name.unique()\n",
    "    sh_in_txt = [is_psc(x,psc_name) for x in sh_in_txt]\n",
    "    \n",
    "    while '' in sh_in_txt:\n",
    "        sh_in_txt.remove('')\n",
    "    \n",
    "    if (psc_name == '') and (len(sh_in_txt) > 1):\n",
    "        return ['MULTIPLE ISSUE - HIGH',sh_in_txt,sh_in_txt], df_bd\n",
    "    elif (psc_name == '') and (len(sh_in_txt) == 1):\n",
    "        psc_name = sh_in_txt[0]\n",
    "    elif (psc_name == '') and (len(sh_in_txt) == 0):\n",
    "        return ['INSUFFICIENT INFO - LOW',sh_in_txt,sh_in_txt],df_bd\n",
    "    \n",
    "    count_found = len(sh_in_txt)\n",
    "    count_org = 0\n",
    "    \n",
    "    # Fetching extra info thats needed later on\n",
    "    df_noc_red = df_off[df_off.CONTACT_ID == cont_id]\n",
    "    df_noc_red['merged_name'] = [merge_names_nat(x).replace('  ',' ') for x in df_noc_red[['OFFICER_FORENAME_1','OFFICER_FORENAME_2','OFFICER_SURNAME']].values]\n",
    "    corp_id = df[df.PSC_DISCREPANCY_ID == psc_id].CORPORATE_BODY_ID.iloc[0]\n",
    "    shs = df_noc_red[df_noc_red.CONTACT_ID == cont_id].merged_name.unique()\n",
    "    shs = remove_space_list(shs)\n",
    "    sh_in_txt = sh_in_txt if count_found > 0 else [is_psc(get_sh_from_shs(psc_name,shs),psc_name)]\n",
    "    sh_in_txt = sh_in_txt if sh_in_txt[0] != None else [psc_name.lower()]\n",
    "    #print(\"corp: \",corp_id)\n",
    "    #print(\"contact: \",cont_id)\n",
    "    \n",
    "    # need to confirm singulart organisation is spoken about if psc is org...\n",
    "    org_parts = df_bd[df_bd.type_tag == 'ORG'].index.values\n",
    "    orgs = []\n",
    "    if psc_name.lower() in ' '.join(df_bd.loc[org_parts,'word']): # below is logic for dealing with non identified organisations in text\n",
    "        org_inds = df_bd[(df_bd.type_tag == 'ORG') & (df_bd.sh_name.isna())]\n",
    "        if org_inds.shape[0] != 0:\n",
    "            prev_ind = org_inds.index.values[0] -1\n",
    "            current_org = []\n",
    "            for ind in org_inds.index.values:\n",
    "                if ind - 1 == prev_ind:\n",
    "                    current_org.append(org_inds.loc[ind,'word'])\n",
    "                else:\n",
    "                    orgs.append(' '.join(current_org))\n",
    "                    current_org = []\n",
    "                    current_org.append(org_inds.loc[ind,'word'])\n",
    "                prev_ind = ind\n",
    "                \n",
    "            orgs.append(' '.join(current_org))    \n",
    "            orgs = list(set(orgs))\n",
    "            orgs = remove_space_list(orgs)\n",
    "            for org in orgs: # if any of the orgs arent in the shareholders store or arent the psc name then we know multiple                   \n",
    "                if (psc_name != is_psc(org,psc_name)) or (org not in shs):\n",
    "                    count_org += 1\n",
    "                    break\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Check if only 'psc' or 'pscs' stated in text\n",
    "    if (count_found == 1) and (sh_in_txt[0] == 'PERSONS'):\n",
    "        sh_in_txt = [get_sh_from_shs(psc_name,shs)]\n",
    "        \n",
    "    if (count_found == 1) and (sh_in_txt[0] == None):\n",
    "        sh_in_txt = [get_sh_from_shs(psc_name,shs)]\n",
    "        \n",
    "    count_found = len(sh_in_txt) + count_org\n",
    "    \n",
    "    # Fetching Relevant Information from PSC Register info (officer information)\n",
    "    df_noc_red = df_noc_red.loc[[df_noc_red[df_noc_red.NATURE_OF_CONTROL_TYPE_ID == x].first_valid_index() for x in df_noc_red.NATURE_OF_CONTROL_TYPE_ID.unique()]]\n",
    "    \n",
    "    # Checking if multiple issue\n",
    "    if count_found > 1:\n",
    "        return ['MULTIPLE ISSUE - HIGH',sh_in_txt+orgs,shs],df_noc_red\n",
    "    \n",
    "    # Defining different key patterns of markers for each phrase\n",
    "    key_patterns = {'NOC':['SH/VOTE OWNERSHIP JOIN VOTING VOTING GREATER DIGIT NEGATIVE GREATER DIGIT', # ORDER MATTERS\n",
    "                                      'GREATER DIGIT LESSER DIGIT SH/VOTE OWNERSHIP JOIN VOTING VOTING',\n",
    "                                      'DIGIT GREATER SH/VOTE OWNERSHIP JOIN VOTING VOTING',\n",
    "                                      'OWNERSHIP GREATER DIGIT OWNERSHIP JOIN VOTING VOTING',\n",
    "                                      'VOTING VOTING JOIN OWNERSHIP OWNERSHIP PERCENT DIGIT DIGIT',\n",
    "                                      'OWNERSHIP JOIN VOTING VOTING GREATER DIGIT',\n",
    "                                      'OWNERSHIP GREATER DIGIT NEGATIVE GREATER PERCENT DIGIT',\n",
    "                                      'SH/VOTE OWNERSHIP GREATER DIGIT NEGATIVE GREATER DIGIT',\n",
    "                                      'OWNERSHIP GREATER DIGIT LESSER DIGIT',\n",
    "                                      'GREATER DIGIT NEGATIVE GREATER DIGIT OWNERSHIP',\n",
    "                                      'OWNERSHIP GREATER DIGIT NEGATIVE GREATER DIGIT',\n",
    "                                      'SIC GREATER DIGIT NEGATIVE GREATER DIGIT',\n",
    "                                      'OWNERSHIP PERCENT DIGIT JOIN DIGIT',\n",
    "                                      'OWNERSHIP PERCENT DIGIT DIGIT',\n",
    "                                      'SH/VOTE OWNERSHIP DIGIT DIGIT',\n",
    "                                      'OWNERSHIP PERCENT DIGIT DIGIT',\n",
    "                                      'OWNERSHIP LESSER PERCENT DIGIT JOIN GREATER DIGIT',\n",
    "                                      'SH/VOTE OWNERSHIP GREATER DIGIT',\n",
    "                                      'SIC DIGIT GREATER SH/VOTE OWNERSHIP',\n",
    "                                      'NEGATIVE GREATER DIGIT OWNERSHIP', # the removal case\n",
    "                                      'OWNERSHIP DIGIT GREATER',\n",
    "                                      'OWNERSHIP PERSON DIGIT OWNERSHIP',\n",
    "                                      'SIC GREATER DIGIT OWNERSHIP',\n",
    "                                      'PERSON DIGIT OWNERSHIP',\n",
    "                                      'PERSON DIGIT SH/VOTE OWNERSHIP',\n",
    "                                      'OWNERSHIP DIGIT OWNERSHIP',\n",
    "                                      'SIC DIGIT GREATER STOP',\n",
    "                                      'OWNERSHIP DIGIT OWNERSHIP',\n",
    "                                      #'GREATER DIGIT LESSER DIGIT',\n",
    "                                      #'GREATER DIGIT NEGATIVE GREATER DIGIT',\n",
    "                                      'DIGIT GREATER OWNERSHIP',\n",
    "                                      'DIGIT OWNERSHIP',\n",
    "                                      'OWNERSHIP PERCENT DIGIT',\n",
    "                                      'OWNERSHIP DIGIT OWNERSHIP',\n",
    "                                      'SIC DIGIT OWNERSHIP GREATER',\n",
    "                                      'SIC GREATER DIGIT',\n",
    "                                      'OWNERSHIP DIGIT SIC',\n",
    "                                      'OWNERSHIP DIGIT STOP',\n",
    "                                      'DIGIT GREATER SH/VOTE OWNERSHIP',\n",
    "                                      'OWNERSHIP STOP DIGIT STOP',\n",
    "                                      'DIGIT VOTING VOTING'], \n",
    "                   'VR':['VOTING VOTING GREATER DIGIT NEGATIVE GREATER PERCENT DIGIT',\n",
    "                                  'VOTING VOTING GREATER DIGIT NEGATIVE GREATER DIGIT',\n",
    "                                  'VOTING VOTING GREATER DIGIT LESSER DIGIT',\n",
    "                                  'VOTING VOTING PERCENT DIGIT JOIN DIGIT',\n",
    "                                  'VOTING VOTING PERCENT DIGIT DIGIT',\n",
    "                                  'VOTING VOTING DIGIT DIGIT',\n",
    "                                  'VOTING VOTING DIGIT PERCENT DIGIT',\n",
    "                                  'GREATER DIGIT NEGATIVE GREATER DIGIT VOTING VOTING',\n",
    "                                  'VOTING VOTING GREATER DIGIT NEGATIVE DIGIT',\n",
    "                                  'VOTING VOTING LESSER PERCENT DIGIT JOIN GREATER DIGIT',\n",
    "                                  'VOTING VOTING GREATER DIGIT',\n",
    "                                   'VOTING VOTING DIGIT GREATER',\n",
    "                                   'DIGIT OWNERSHIP JOIN VOTING VOTING STOP',\n",
    "                                    'VOTING VOTING PERCENT DIGIT'],\n",
    "                   'SIC':['NEGATIVE SIC SIC SIC','SIC SIC JOIN NEGATIVE SIC','SIC SIC NEGATIVE SIC','SIC SIC SIC']}\n",
    "    \n",
    "    # please note the appove has been created by successive runs on various psc ids and where information has not been captured we redefined\n",
    "    #       the patterns. i.e appended\n",
    "        \n",
    "    tags = df_bd.type_tag.values\n",
    "    per_vals = df_bd.per_value.values\n",
    "    words=df_bd.word.values\n",
    "    \n",
    "    # Searching for key patterns...\n",
    "    found_pattern = False\n",
    "    found_key_patterns = dict.fromkeys(key_patterns.keys()) # to be appended to with our found items\n",
    "    for key in key_patterns.keys(): # iterates through keys\n",
    "        found_key_patterns[key] = [] # sets our found dict to contain lists so we can append\n",
    "\n",
    "    for key in key_patterns.keys():\n",
    "        for marker in key_patterns[key]: # iterates through strings to match in each key\n",
    "            tags_joined = ' '.join(tags)\n",
    "\n",
    "            while marker in tags_joined:  \n",
    "                if key in ['VR','NOC']:\n",
    "                    found_pattern = True\n",
    "                marker_arr = np.array(marker.split(' ')) # turns to array for indexing \n",
    "                inds_of_marker = search_sequence_numpy(tags,marker_arr) # searches for indices of sequence in original\n",
    "\n",
    "                # Checking single sequence... and reducing if so\n",
    "                for i in range(1,len(inds_of_marker)):\n",
    "                    if inds_of_marker[i]-1 != inds_of_marker[i-1]:\n",
    "                        inds_of_marker = inds_of_marker[:i]\n",
    "                        break\n",
    "                \n",
    "                \n",
    "                if key == 'SIC': # if SIC we dont search for digits\n",
    "                    if 'NEGATIVE' in marker:\n",
    "                        found_key_patterns[key] = [False] if marker.index('NEGATIVE') < marker.index('SIC') else [True]\n",
    "                    else:\n",
    "                        found_key_patterns[key] = [True]\n",
    "    \n",
    "                    tags = np.delete(tags,inds_of_marker)\n",
    "                    words = np.delete(words,inds_of_marker)\n",
    "                    tags_joined = ' '.join(tags)\n",
    "                    continue\n",
    "    \n",
    "                digit_locs = np.where(marker_arr == 'DIGIT')\n",
    "                ind_digit = [inds_of_marker[k] for k in digit_locs] # then gets indices of digit markers\n",
    "                digits = per_vals[ind_digit] # returns the percentages that are being spoke about\n",
    "                \n",
    "                if 'LESSER' in marker:\n",
    "                    if marker.index('LESSER') < marker.index('GREATER'):\n",
    "                        digits = [digits[1],digits[0]]\n",
    "                \n",
    "                noc_and_vr = False\n",
    "                if key == 'NOC':\n",
    "                    if 'VOTING' in marker.split(' '):\n",
    "                        noc_and_vr = True\n",
    "                \n",
    "                if noc_and_vr == True:\n",
    "                    found_key_patterns[key].append([marker,list(digits)]) \n",
    "                    found_key_patterns['VR'].append([marker,list(digits)]) \n",
    "                else:\n",
    "                    found_key_patterns[key].append([marker,list(digits)]) # appends found items to dict\n",
    "                            \n",
    "\n",
    "                # reducing dataset so multiple matches aren't confused\n",
    "                tags = np.delete(tags,inds_of_marker)\n",
    "                words = np.delete(words,inds_of_marker)\n",
    "                per_vals = np.delete(per_vals,inds_of_marker)\n",
    "                \n",
    "                # for checking again...\n",
    "                tags_joined = ' '.join(tags)\n",
    "                \n",
    "\n",
    "    #print(found_key_patterns)\n",
    "    if found_pattern == True:\n",
    "        # Determining which categories have been found...\n",
    "        found_tags = []\n",
    "        for key in found_key_patterns.keys():\n",
    "            if len(found_key_patterns[key]) > 0:\n",
    "                found_tags.append(key)\n",
    "    else:\n",
    "        # checking if voting is mentioned, if not then we assume they are mentioning share ownership\n",
    "        if ('VOTING' not in tags):\n",
    "            if ('DIGIT' in tags) or ('PERCENT' in tags):\n",
    "                nums_extract = df_bd[~df_bd.per_value.isna()].per_value.values\n",
    "                found_pattern = True if len(nums_extract) > 0 else found_pattern\n",
    "                # grouping those that should go together...\n",
    "                ordering = [25,50,75]\n",
    "                i = 0\n",
    "                while i < len(nums_extract):\n",
    "                    current_num = nums_extract[i]\n",
    "                    if current_num in ordering:\n",
    "                        num_ind = ordering.index(current_num)\n",
    "                        \n",
    "                        if i < len(nums_extract) - 1:\n",
    "                            if nums_extract[i+1] in ordering: # i.e\n",
    "                                num_2_ind = ordering.index(nums_extract[i+1])\n",
    "                            else:\n",
    "                                found_key_patterns['NOC'].append([None,[current_num]]) # appends in correct format\n",
    "                                i += 1\n",
    "                                continue\n",
    "                        \n",
    "                            if num_2_ind == num_ind + 1:\n",
    "                                found_key_patterns['NOC'].append([None,[current_num,nums_extract[i+1]]]) # the case where a range has been found\n",
    "                                i += 2\n",
    "                                continue\n",
    "                            else:\n",
    "                                found_key_patterns['NOC'].append([None,[current_num]])\n",
    "                                i += 1\n",
    "                                continue\n",
    "                    \n",
    "                    found_key_patterns['NOC'].append([None,[current_num]])\n",
    "                    i += 1\n",
    "                    continue\n",
    "                    \n",
    "        found_tags = []\n",
    "        for key in found_key_patterns.keys():\n",
    "            if len(found_key_patterns[key]) > 0:\n",
    "                found_tags.append(key)\n",
    "    \n",
    "    # checking if all items have been caught...\n",
    "    # we only want to do this when single type is mentioned as multi types should capture but also cause confusion\n",
    "    \n",
    "    if len(found_tags) <= 1:\n",
    "        per_vals = [per for per in per_vals if (per>10 and per <=100)]\n",
    "        tag_to_use = found_tags[0] if len(found_tags) == 1 else 'NOC'\n",
    "        \n",
    "        for per in per_vals:\n",
    "            found_key_patterns[tag_to_use].append([None,[per]])\n",
    "                        \n",
    "    to_return_dict = dict.fromkeys(found_key_patterns.keys())\n",
    "    for key in to_return_dict:\n",
    "        to_return_dict[key] =[]\n",
    "    print(found_key_patterns)\n",
    "    # Now we have our found tags we must check these controls are on the register for the individual,\n",
    "    # Note we first check we have a singular person being discussed\n",
    "    df_noc_red.merged_name = df_noc_red.merged_name.apply(lambda x: is_psc(x,sh_in_txt[0]))\n",
    "\n",
    "    if count_found == 1:\n",
    "        df_psc = df_noc_red[df_noc_red.merged_name == sh_in_txt[0].lower()] if len(df_noc_red.merged_name.unique()) > 1 else df_noc_red\n",
    "        \n",
    "        # exit here is due to more than 3 controls listed which is not allowed\n",
    "        if df_psc[df_psc.merged_name == sh_in_txt[0].lower()].shape[0] > 3:\n",
    "            chips_controls = get_controls(df_psc,multi = True)\n",
    "            \n",
    "            for key in ['NOC','VR']:\n",
    "                if len(found_key_patterns[key]) == 0:\n",
    "                    found_key_patterns[key] = None\n",
    "                else:\n",
    "                    new = []\n",
    "                    for i in found_key_patterns[key]:\n",
    "                        new.append(i[1])\n",
    "                    found_key_patterns[key] = new\n",
    "                            \n",
    "            return ['TOO MANY CONTROLS - HIGH',format_chips_op(found_key_patterns), format_chips_op(chips_controls)],df_noc_red\n",
    "        else:\n",
    "            # here we want to state the shareholders controls\n",
    "            chips_controls = get_controls(df_psc)\n",
    "            \n",
    "        \n",
    "        cats = df_psc.TYPE.unique()\n",
    "        \n",
    "        difference_found = False\n",
    "        difference_found_in = [] # for approapriate priority in output\n",
    "        # now we go through found tags\n",
    "        for tag in found_tags:\n",
    "            if tag not in cats:\n",
    "                items = found_key_patterns[tag]\n",
    "                to_add = [item[1] for item in items] if tag != 'SIC' else items[0]\n",
    "                to_return_dict[tag].append(to_add)\n",
    "                difference_found = True\n",
    "                difference_found_in.append(tag)\n",
    "                \n",
    "            elif tag != 'SIC':\n",
    "                # getting lower and upper bounds...\n",
    "                bounds = df_psc[df_psc.TYPE == tag][['LB','UB']].values[0]\n",
    "                \n",
    "                if bounds[1] is np.nan: # if we have top cat i.e 75% or more\n",
    "                    bounds[1] = 100\n",
    "                \n",
    "                to_check = found_key_patterns[tag]\n",
    "                \n",
    "                for items in to_check: # checks through all found patterns\n",
    "                    item = items[1]\n",
    "                    if len(item) == 1:\n",
    "                        if item[0] >= 75:\n",
    "                            if bounds[0] != 75:\n",
    "                                to_return_dict[tag].append(item)\n",
    "                                difference_found = True\n",
    "                                difference_found_in.append(tag)\n",
    "                            else:\n",
    "                                continue\n",
    "                        elif item[0] == 25:\n",
    "                            continue\n",
    "                        else:\n",
    "                            if (item[0] > bounds[0]) and (item[0] < bounds[1]):\n",
    "                                continue\n",
    "                            else:\n",
    "                                to_return_dict[tag].append(item)\n",
    "                                difference_found = True\n",
    "                                difference_found_in.append(tag)\n",
    "                    else:\n",
    "                        if (item[0] == bounds[0]) and (item[1] == bounds[1]):\n",
    "                            continue\n",
    "                        elif (item[0] == bounds[0]) and (item[1] == 100):\n",
    "                            continue\n",
    "                        else:\n",
    "                            to_return_dict[tag].append(item)\n",
    "                            difference_found = True\n",
    "                            difference_found_in.append(tag)\n",
    "            elif tag == 'SIC':\n",
    "                to_return_dict[tag] = found_key_patterns[tag]\n",
    "    \n",
    "\n",
    "    # checking if difference in sic\n",
    "    if (found_key_patterns['SIC'] != []) and (chips_controls['SIC'] != found_key_patterns['SIC'][0]):\n",
    "        difference_found = True\n",
    "        \n",
    "    if (limited_tag == True) and (chips_controls['NOC'] != None):\n",
    "        return ['LIMITED BY GUARENTEE - HIGH',None,format_chips_op(chips_controls)],df_noc_red\n",
    "    \n",
    "                \n",
    "    if difference_found == True:\n",
    "        for key in ['NOC','VR']:\n",
    "                if len(to_return_dict[key]) == 0:\n",
    "                    to_return_dict[key] = None\n",
    "                else:\n",
    "                    #checking successive list\n",
    "                    if len(to_return_dict[key]) == 1:\n",
    "                        if type(to_return_dict[key][0]) == list:\n",
    "                            to_return_dict[key] = to_return_dict[key][0][0] if type(to_return_dict[key][0][0]) == list else to_return_dict[key][0]\n",
    "\n",
    "        # checking where differences are...\n",
    "        if 'NOC' in difference_found_in:\n",
    "            tag_to_give = ' SHARES - HIGH'\n",
    "        else:\n",
    "            tag_to_give = ' VOTING OR RTA - LOW' if limited_tag != True else ' VOTING OR RTA - HIGH' \n",
    "        \n",
    "        return ['DIFFERENCE FOUND' + tag_to_give,format_chips_op(to_return_dict),format_chips_op(chips_controls)],df_noc_red\n",
    "    else:\n",
    "        # checking patterns have been found...\n",
    "        if found_pattern == True:\n",
    "            # preping the return dict\n",
    "            for key in ['NOC','VR']:\n",
    "                if len(to_return_dict[key]) == 0:\n",
    "                    to_return_dict[key] = None\n",
    "                else:\n",
    "                    #checking successive list\n",
    "                    if len(to_return_dict[key]) == 1:\n",
    "                        if type(to_return_dict[key][0]) == list:\n",
    "                            to_return_dict[key] = to_return_dict[key][0][0] if type(to_return_dict[key][0][0]) == list else to_return_dict[key][0]\n",
    "            \n",
    "            # checking trustee, firm, person\n",
    "            # first get the type for NOC and voting\n",
    "            df_psc = df_noc_red[df_noc_red.merged_name == sh_in_txt[0].lower()]\n",
    "            noc_type = list(set([item for item in ['trustee','person','firm'] if item in ' '.join(df_psc.DESCRIPTION.values).lower()]))\n",
    "            noc_type_in_txt = list(set([item for item in ['trustee','person','firm'] if item in df[df.PSC_DISCREPANCY_ID == psc_id].discrepancy_detail.iloc[0].lower() ]))\n",
    "            \n",
    "            trigger_noc = False\n",
    "            for item in noc_type_in_txt:\n",
    "                if item not in noc_type:\n",
    "                    trigger_noc = True\n",
    "                    \n",
    "            if (len(noc_type) > 1) or (trigger_noc == True):\n",
    "                return ['TRUSTEE, PERSON, OR FIRM DIFFERENCE - HIGH',format_chips_op(to_return_dict),format_chips_op(chips_controls)],df_noc_red\n",
    "            \n",
    "            return ['MATCHED - NONE',format_chips_op(to_return_dict),format_chips_op(chips_controls)],df_noc_red\n",
    "        else:\n",
    "            # Checking for removed tags\n",
    "            txt = df[df.PSC_DISCREPANCY_ID == psc_id].discrepancy_detail.iloc[0].lower()\n",
    "            rem_tags = ['since been removed','please remove','no longer psc','no longer a psc','remove psc','removal of psc','psc removal','no longer psc','no longer a shareholder','remove this person']\n",
    "            for item in rem_tags:\n",
    "                if (item in txt) or (rem_tag == True):\n",
    "                    return ['REMOVAL - HIGH',psc_name,psc_name],df_noc_red\n",
    "            \n",
    "            \n",
    "            # checking controls and stated controls where no patterns found and no % values extracted\n",
    "            count_of_tags = df_bd.type_tag.value_counts()\n",
    "            NOC = count_of_tags['OWNERSHIP'] if 'OWNERSHIP' in count_of_tags.index else 0\n",
    "            VR = count_of_tags['VOTING'] if 'VOTING' in count_of_tags.index else 0\n",
    "            SIC = count_of_tags['SIC'] if 'SIC' in count_of_tags.index else 0\n",
    "            \n",
    "            NOC = True if NOC > 0 else False\n",
    "            VR = True if VR > 0 else False\n",
    "            SIC = True if SIC > 1 else False # this is 1 as SIC always mentioned twice for SIC cases but can be once for non SIC\n",
    "            \n",
    "            chips_NOC = True if chips_controls['NOC'] != None else False\n",
    "            chips_VR = True if chips_controls['VR'] != None else False\n",
    "            chips_SIC = True if chips_controls['SIC'] == True else False\n",
    "            \n",
    "            chips = [chips_NOC,chips_VR,chips_SIC]\n",
    "            text_ex = [NOC,VR,SIC]\n",
    "            \n",
    "            if (chips == [True,False,True] ) and (VR == True) : # reported VR missing, holds NOC and SIC in CHIPS\n",
    "                return ['WITHOUT VOTING RIGHTS - LOW',None,format_chips_op(chips_controls)],df_noc_red\n",
    "            \n",
    "            elif (chips == [False,False,True]) and (VR == True) and (NOC == False): # reported VR missing, holds SIC only\n",
    "                return ['WITHOUT VOTING RIGHTS (SIC IN CHIPS) - HIGH',None,format_chips_op(chips_controls)],df_noc_red\n",
    "            \n",
    "            elif (NOC == True) and (chips[0] == False): # NOC present but not in CHIPS\n",
    "                return ['WITHOUT SH - HIGH',None,format_chips_op(chips_controls)],df_noc_red\n",
    "            \n",
    "            elif (VR == True) and (sum(chips) == 0):\n",
    "                return ['WITHOUT VOTING RIGHTS - LOW',None,format_chips_op(chips_controls)],df_noc_red\n",
    "            \n",
    "            elif ('remove' in df_bd.word.values) or ('removed' in df_bd.word.values):\n",
    "                return ['REMOVAL - HIGH',None,format_chips_op(chips_controls)],df_noc_red\n",
    "            \n",
    "            elif ((NOC == True) and (chips[0] == True)) or ((VR == True) and (chips[1] == True)): # have we found missing logic\n",
    "                return ['MISSING CONTROLS FOUND - NONE',None,format_chips_op(chips_controls)],df_noc_red\n",
    "            \n",
    "            return ['INSUFFICIENT INFO - LOW',None,format_chips_op(chips_controls)],df_noc_red # if none of the above...\n",
    "                \n",
    "    return ['tag',found_key_patterns], df_noc_red\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e1a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noc_prio(psc_id,df):\n",
    "    print(\"CURRENT ID: \",psc_id)\n",
    "    df_bd,psc_name,rem_tag,lim_tag = text_breakdown(df,psc_id)\n",
    "    op,df_noc_red = breakdown_to_op(psc_id,df_bd,df,psc_name,rem_tag,lim_tag)\n",
    "    \n",
    "    index = df[df.PSC_DISCREPANCY_ID == psc_id].index[0]\n",
    "    \n",
    "    \n",
    "    df.loc[index,'priority_explained'] = op[0].split(' - ')[0]\n",
    "    df.loc[index,'priority'] = op[0].split(' - ')[1]\n",
    "    df.loc[index,'material_nonmaterial'] = 'MATERIAL' if 'NONE' not in op[0].split(' - ')[1] else 'NON-MATERIAL'\n",
    "\n",
    "    if 'REMOVAL' in op[0]:\n",
    "        df.loc[index,'CHIPS_value'] = op[1]\n",
    "        return op[2]\n",
    "    \n",
    "    else:\n",
    "        df.loc[index,'CHIPS_value'] = str(op[2]).replace('[]','None').replace('{','').replace('}','').replace(']','%').replace('[','').replace(',','% -').replace('None%','None').replace('nan%','100%').replace('%%','%').replace(\"'%\",\"'\").replace('%%','%').replace('True%','True').replace('False%','False').replace('%%','%')\n",
    "        return str(op[1]).replace('[]','None').replace('{','').replace('}','').replace(']','%').replace('[','').replace(',','% -').replace('None%','None').replace('nan%','100%').replace('%%','%').replace(\"'%\",\"'\").replace('%%','%').replace('True%','True').replace('False%','False').replace('%%','%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ce339",
   "metadata": {},
   "source": [
    "# NATIONALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62cb1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nationality_compare(psc_id,df, trace = False):\n",
    "    #print(\"\\n=======================================================================================================================\")\n",
    "    # fetching discrepancy info\n",
    "    txt = df[df.PSC_DISCREPANCY_ID == psc_id].discrepancy_detail.iloc[0]#.lower()\n",
    "    psc_name = df[df.PSC_DISCREPANCY_ID == psc_id].extract_psc_name.iloc[0].lower()\n",
    "    cont_id = df[df.PSC_DISCREPANCY_ID == psc_id].CONTACT_ID.iloc[0]\n",
    "    comp_num = df[df.PSC_DISCREPANCY_ID == psc_id].COMPANY_NUMBER.iloc[0]\n",
    "    corp_id = df[df.PSC_DISCREPANCY_ID == psc_id].CORPORATE_BODY_ID.iloc[0]\n",
    "    \n",
    "    if trace == True:\n",
    "        print(\"TEXT : \",txt)\n",
    "        print(\"NAME : \",psc_name)\n",
    "        print(\"CONTACT : \",cont_id)\n",
    "    \n",
    "    \n",
    "    #checking for NOC mentions\n",
    "    noc_buzzwords = ['nature of control','ownership','shares','voting', '%']           \n",
    "    noc_found = any([True if x in txt.lower() else False for x in noc_buzzwords]) == True\n",
    "    \n",
    "    # fetching SH info\n",
    "    df_cont = df_off[df_off.CONTACT_ID == cont_id]\n",
    "    \n",
    "    # preprocessing text\n",
    "    remove_punc = ['\\n','\\r','!','.',',','\"',\"'\",'(',')',';',':','-','&']\n",
    "    for punc in remove_punc:\n",
    "        txt = txt.replace(punc,' ')\n",
    "        \n",
    "    txt_split = txt.split(' ')\n",
    "    while '' in txt_split:\n",
    "        txt_split.remove('')\n",
    "    \n",
    "    \n",
    "    # get pos tagging\n",
    "    pos_tags = get_pos_tags(txt,nlp,nationalities = nationalities,reduce_ents = False, nat = True)\n",
    "    \n",
    "    norp_items = list(set(pos_tags['NORP']))\n",
    "    \n",
    "    for nat in nationalities:\n",
    "        nat = nat.lower()\n",
    "        while nat[0] == ' ':\n",
    "            nat = nat[1:]\n",
    "        while nat[-1] == ' ':\n",
    "            nat = nat[:-1]\n",
    "            \n",
    "        if (nat in txt.lower()) and (nat not in norp_items):\n",
    "            norp_items.append(nat)\n",
    "    \n",
    "    # sometimes country captured as ORG, adding these to selection\n",
    "    org_items = list(set(pos_tags['ORG']))\n",
    "\n",
    "    for item in org_items:\n",
    "        item = item.lower()\n",
    "        if (item in nationalities) and (item not in norp_items):\n",
    "            norp_items.append(item)\n",
    "                \n",
    "    # the sri lanka check as spacy doesnt like picking this up\n",
    "    if ('sri lanka' in txt.lower()) or ('sri lankan' in txt.lower()):\n",
    "        if ('sri lanka' not in norp_items) or ('sri lankan' not in norp_items):\n",
    "            norp_items.append('sri lanka')\n",
    "            \n",
    "    # changing all to most common adjectival for country\n",
    "    reduced_items = []\n",
    "    for norp in norp_items:\n",
    "        norp = norp.lower()\n",
    "        if norp in df_nat_and_adj.country.values:\n",
    "            new_name = df_nat_and_adj[df_nat_and_adj.country == norp].adjectivals.values[0]\n",
    "            reduced_items.append(new_name)\n",
    "            \n",
    "        elif norp in df_nat_and_adj.adjectivals.values:\n",
    "            our_country = df_nat_and_adj[df_nat_and_adj.adjectivals == norp].country.values[0]\n",
    "            new_name = df_nat_and_adj[df_nat_and_adj.country == our_country].adjectivals.values[0]\n",
    "            reduced_items.append(new_name)\n",
    "            \n",
    "        else:\n",
    "            reduced_items.append(norp)\n",
    "            \n",
    "            \n",
    "    reduced_items = list(set(reduced_items))\n",
    "    norp_orig = reduced_items.copy()\n",
    "    \n",
    "    #print(\"\\nEXTRACTED NORPS: \",reduced_items)\n",
    "    \n",
    "    # get sh\n",
    "    our_sh = get_sh_from_shs(psc_name,df_cont[~df_cont.merged_name.isna()].merged_name.unique())\n",
    "    \n",
    "    if our_sh == None: # if no person found\n",
    "        return [\"PERSON NOT FOUND - HIGH\",['None'],reduced_items]\n",
    "    \n",
    "    our_sh_id = df_cont[df_cont.merged_name == our_sh].OFFICER_ID.values[0]\n",
    "    \n",
    "    # removing nationalities stored from nationalities extracted\n",
    "    our_sh_nat = df_cont[df_cont.OFFICER_ID == our_sh_id].OFFICER_NATIONALITY.apply(lambda x: x.lower() if type(x) == str else '').unique()\n",
    "    our_sh_nat = list(our_sh_nat)\n",
    "    while '' in our_sh_nat:\n",
    "        our_sh_nat.remove('')\n",
    "        \n",
    "    new_nat_sh = []\n",
    "\n",
    "    # for when dual nationality is stored as e.g. \"british,nigerian\"\n",
    "    for nat in our_sh_nat:\n",
    "        if ',' in nat:\n",
    "            nat_split = nat.split(',')\n",
    "            for nat in nat_split:\n",
    "                new_nat_sh.append(nat)\n",
    "        else:\n",
    "            new_nat_sh.append(nat)\n",
    "            \n",
    "    our_sh_nat = list(set(new_nat_sh))\n",
    "\n",
    "    #print(\"SH NAT: \",our_sh_nat)\n",
    "    for nat in our_sh_nat: \n",
    "        if nat in reduced_items:\n",
    "            reduced_items.remove(nat)\n",
    "\n",
    "    # checking dual nationality\n",
    "    if 'dual' in txt.lower():\n",
    "        if (len(our_sh_nat) == 0) or (len(reduced_items) > 0): # if no nationalities listed but dual is mentioned\n",
    "            return ['NOT MATCHED - LOW' if noc_found == False else 'NOC FOUND - HIGH',our_sh_nat,reduced_items]\n",
    "        else: # if mentioned but matched\n",
    "            return ['DUAL NATIONAL MATCHED - NONE' if noc_found == False else 'NOC FOUND - HIGH',our_sh_nat,reduced_items]\n",
    "    \n",
    "    #print(\"REMAINING NATS: \",reduced_items)\n",
    "    \n",
    "    if len(reduced_items) > 0: # remaining items that have not been matched\n",
    "        return ['NOT MATCHED - LOW' if noc_found == False else 'NOC FOUND - HIGH',our_sh_nat,reduced_items]\n",
    "    \n",
    "    elif len(norp_orig) == 0: # if none of the above and none extract then insufficient info to procede\n",
    "        \n",
    "        return ['INSUFFICIENT INFO - LOW' if noc_found == False else 'NOC FOUND - HIGH',our_sh_nat,reduced_items]\n",
    "    \n",
    "    else: # if none of the above then we know\n",
    "        return ['MATCHED - NONE' if noc_found == False else 'NOC FOUND - HIGH',our_sh_nat,reduced_items]\n",
    "    \n",
    "    \n",
    "    return ['ERROR',None,None]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e5b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nationality_prio(psc_id,df):\n",
    "    print(psc_id)\n",
    "    index = df[df.PSC_DISCREPANCY_ID == psc_id].index\n",
    "    op = nationality_compare(psc_id,df)\n",
    "    \n",
    "    df.loc[index,'priority_explained']  = op[0].split(' - ')[0]\n",
    "    df.loc[index,'priority'] = op[0].split(' - ')[1]\n",
    "    df.loc[index,'CHIPS_value'] = ', '.join(op[1])\n",
    "    df.loc[index,'material_nonmaterial'] = 'NON-MATERIAL' if 'NONE' in op[0] else 'MATERIAL'\n",
    "    return ', '.join(op[2]) # returns text_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c12a59d",
   "metadata": {},
   "source": [
    "# DOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a3209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dobs_from_text(psc_id,df_rel,trace = False):\n",
    "    # first check action code...\n",
    "    cont_id = df_rel[df_rel.PSC_DISCREPANCY_ID == psc_id].CONTACT_ID.values[0]\n",
    "    \n",
    "    # Fetching Data\n",
    "    txt_orig = df_rel[df_rel.PSC_DISCREPANCY_ID == psc_id].discrepancy_detail.values[0]\n",
    "    txt = txt_orig.lower()\n",
    "    \n",
    "    comp_num = df_rel[df_rel.PSC_DISCREPANCY_ID == psc_id].COMPANY_NUMBER.values[0]\n",
    "    psc_name = df_rel[df_rel.PSC_DISCREPANCY_ID == psc_id].PSC_NAME.values[0]\n",
    "    corp_id = df_rel[df_rel.PSC_DISCREPANCY_ID == psc_id].CORPORATE_BODY_ID.values[0]\n",
    "    \n",
    "    if type(psc_name) != str:\n",
    "        return [None,None,'NO PSC NAME - NONE']\n",
    "    else:\n",
    "        psc_name = psc_name.lower()\n",
    "    \n",
    "    if trace == True:\n",
    "        print(\"\\n========================================================================================================================================================\")\n",
    "        print(\"PSC ID : \",psc_id)\n",
    "        print(\"PSC Name : \",psc_name)\n",
    "        print(\"COMPANY NUMBER : \",comp_num)\n",
    "        print(\"CORPORATE ID : \",corp_id)\n",
    "        print(\"CONTACT ID : \",cont_id)\n",
    "        print(\"\\nThe text : \")\n",
    "        print(txt_orig)\n",
    "\n",
    "    # minor preprocessing\n",
    "    remove_punc = ['\\n','\\r','!','.',',','year','\"',\"'\",'(',')','dob','ch','month',';',':','-']\n",
    "    for punc in remove_punc:\n",
    "        txt = txt.replace(punc,' ')\n",
    "    \n",
    "    txt_split = txt.split(' ')\n",
    "    while '' in txt_split:\n",
    "        txt_split.remove('')\n",
    "    \n",
    "    # spacy date extraction\n",
    "    pos_tags = get_pos_tags(txt,nlp,reduce_ents = True)\n",
    "    pos_in_txt = [assign_pos(pos_tags,x) for x in txt_split]\n",
    "    \n",
    "    # Setting up date extraction...\n",
    "    month_names = {'january':'01','february':'02','march':'03','april':'04','may':'05','june':'06','july':'07','august':'08','september':'09','october':'10',\n",
    "                  'november':'11','december':'12'}\n",
    "    short_months = {month[:3]:v for month,v in month_names.items() }\n",
    "\n",
    "    end_of_nums = ['st ','nd ','rd ','th '] # for 1st 2nd 3rd 4th replacement to 1,2,3,4\n",
    "    \n",
    "    \n",
    "    # turning txt into df\n",
    "    df_txt = pd.DataFrame({'words':txt_split,'pos':pos_in_txt})\n",
    "    df_txt['tags'] = ['DIGIT' if x.isdigit() else 'MONTH' if x in month_names.keys() else 'MONTH SHORT' if x in short_months.keys() else np.nan for x in txt_split  ]\n",
    "    df_txt.loc[df_txt.tags == 'MONTH','words'] = [month_names[x] for x in df_txt[df_txt.tags == 'MONTH'].words.values]\n",
    "    df_txt.loc[df_txt.tags == 'MONTH SHORT','words'] = [short_months[x] for x in df_txt[df_txt.tags == 'MONTH SHORT'].words.values]\n",
    "    df_txt.loc[df_txt.tags == 'MONTH SHORT','tags'] = 'MONTH'\n",
    "    df_txt.loc[df_txt.tags == 'DIGIT','tags'] = df_txt.loc[df_txt.tags == 'DIGIT','words'].apply(lambda x: 'YEAR' if len(x) == 4 else 'DIGIT')\n",
    "    df_txt.loc[df_txt.tags == 'YEAR','words'] = df_txt.loc[df_txt.tags == 'YEAR','words'].apply(lambda x: int('19'+str(x)) if len(x) == 2 else x)\n",
    "    \n",
    "    # checking surrounding indices if YEAR - MONTH - DAY formatting\n",
    "    year_inds = df_txt[df_txt.tags == 'YEAR'].index\n",
    "    for ind in year_inds:\n",
    "        if ind+1 < df_txt.shape[0]:\n",
    "            tag = df_txt.loc[ind+1,'tags'] \n",
    "            if tag == 'DIGIT':\n",
    "                val = int(df_txt.loc[ind+1,'words'])\n",
    "                if (val <= 12) and (val > 0):\n",
    "                    df_txt.loc[ind+1,'tags'] = 'MONTH'\n",
    "                    \n",
    "    # final sweep for missed dates...\n",
    "    for i in range(df_txt.shape[0]):\n",
    "        word = df_txt.loc[i,'words']\n",
    "        \n",
    "        if '/' in word:\n",
    "            word_split = word.split('/')\n",
    "        elif '-' in word:\n",
    "            word_split = word.split('-')\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        if all([part.isdigit() for part in word_split]) == True:\n",
    "            df_txt.loc[i,'pos'] = 'DATE'\n",
    "    \n",
    "    df_txt['to_keep'] = [False if (type(x) != str) and (type(y) != str) else True for x,y in df_txt[['pos','tags']].values]\n",
    "    df_txt = df_txt[df_txt.to_keep == True][['words','pos','tags']]\n",
    "    df_txt =df_txt.reset_index(drop=True)\n",
    "    \n",
    "    whole_dates = df_txt[(df_txt.tags.isna()) & (df_txt.pos == 'DATE')].words.values\n",
    "    months = list(df_txt[df_txt.tags == 'MONTH'].words.values)\n",
    "    years = list(df_txt[df_txt.tags == 'YEAR'].words.values)\n",
    "    \n",
    "    #print(whole_dates)\n",
    "    for date in whole_dates:\n",
    "        date = date.replace('-',' ').replace('/',' ')\n",
    "        date_split = date.split(' ')\n",
    "        \n",
    "        if len(date_split) == 1:\n",
    "            continue\n",
    "        \n",
    "        year_last = True\n",
    "        \n",
    "\n",
    "        if (len(date_split[0]) == 4):\n",
    "            years.append(date_split[0])\n",
    "            year_last = False\n",
    "        elif date_split[0].isdigit():\n",
    "            if  (int(date_split[0]) > 31):\n",
    "                years.append(date_split[0])\n",
    "                year_last = False\n",
    "            else:\n",
    "                years.append(date_split[-1])\n",
    "            \n",
    "        if year_last == True:\n",
    "            months.append(date_split[-2])\n",
    "        else:\n",
    "            months.append(date_split[1])\n",
    "        \n",
    "    # check if month only or year only or both\n",
    "    type_of_rep = 'Both' if (len(months)*len(years) > 0) else 'Year' if len(years) > 0 else 'Month'\n",
    "    \n",
    "    # fetch sh information\n",
    "    for title in ['dr','mr','mrs','mx','ms']:\n",
    "        psc_name = psc_name.replace(title,'')\n",
    "    \n",
    "    sh_info = df_off[df_off.CONTACT_ID == cont_id].reset_index(drop=True)\n",
    "    if sh_info.shape[0] == 0:\n",
    "        return [None, None, 'NO CHIPS VALUE FOUND - HIGH']\n",
    "    \n",
    "    sh_info['OFFICER_DATE_OF_BIRTH'] = pd.to_datetime(sh_info['OFFICER_DATE_OF_BIRTH'],errors = 'coerce')\n",
    "    sh_info = sh_info.fillna('')\n",
    "    sh_info['merged_name'] = [(sh_info.loc[i,'OFFICER_FORENAME_1'] +' '+ sh_info.loc[i,'OFFICER_FORENAME_2'] +' '+ sh_info.loc[i,'OFFICER_SURNAME']).lower() for i in range(0,sh_info.shape[0])]\n",
    "    \n",
    "    # selecting relevant sh\n",
    "    shs = sh_info.merged_name.unique()\n",
    "    sh_scores = np.zeros_like(shs)\n",
    "    psc_split = psc_name.split(' ')\n",
    "    for i in range(0,len(shs)) :\n",
    "        sh = shs[i]\n",
    "        sh_split = sh.split(' ')\n",
    "        for part in psc_split:\n",
    "            if part in sh_split:\n",
    "                sh_scores[i] +=1\n",
    "    \n",
    "    our_sh = get_sh_from_shs(psc_name,sh_info[~sh_info.merged_name.isna()].merged_name.unique())\n",
    "    our_sh_id = sh_info[sh_info.merged_name == our_sh].OFFICER_ID.values[0]\n",
    "    \n",
    "    our_dob = sh_info[sh_info.OFFICER_ID == our_sh_id].OFFICER_DATE_OF_BIRTH.unique()\n",
    "    if len(our_dob) > 1:\n",
    "        to_return_dob = []\n",
    "        for dob in our_dob:\n",
    "            to_return_dob.append(str(dob)[:10])\n",
    "        \n",
    "        the_issue = {'month':months ,'year':years }\n",
    "        return [to_return_dob,the_issue,'MANY DOB SINGLE OFFICER - HIGH']\n",
    "    \n",
    "    our_dob = our_dob[0] if len(our_dob) == 1 else our_dob\n",
    "    \n",
    "    our_mon = our_dob.astype('datetime64[M]').astype(int) %12+1\n",
    "    our_year = our_dob.astype('datetime64[Y]').astype(int) +1970\n",
    "\n",
    "    if int(str(our_year)[-2:]) > 22:\n",
    "        our_year = int('19'+str(our_year)[-2:])\n",
    "    our_dob = str(our_year)+'-'+str(our_mon) if len(str(our_mon)) == 2 else str(our_year)+'-0'+str(our_mon)\n",
    "    \n",
    "    # checking differences\n",
    "    months_issue = False\n",
    "    years_issue = False\n",
    "    issue_mon = []\n",
    "    issue_yr = []\n",
    "    for mon in months:\n",
    "        if mon.isdigit() == False:\n",
    "            continue\n",
    "        if (int(mon) != our_mon) and (type(mon) != None):\n",
    "            months_issue = True\n",
    "            issue_mon.append(mon)\n",
    "    \n",
    "    for year in years:\n",
    "        if year.isdigit() == False:\n",
    "            continue\n",
    "        if (int(year) != our_year) and (type(year) != None):\n",
    "            years_issue = True\n",
    "            issue_yr.append(year)\n",
    " \n",
    "    \n",
    "    the_issue = {'month':issue_mon ,'year':issue_yr }\n",
    "    issue = 'DIFFERENCE FOUND - HIGH' if (months_issue == True) or (years_issue == True) else 'MATCHED - NONE'\n",
    "\n",
    "    return [our_dob,the_issue,issue] # op of order : op[0] = CHIPS_value, op[1] = text_difference, op[2] = tells us if there is an issue or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb87edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dob_prio(psc_id,df):\n",
    "    print(\"CURRENT ID: \",psc_id)\n",
    "\n",
    "    index = df[df.PSC_DISCREPANCY_ID == psc_id].index[0]\n",
    "    \n",
    "    op = get_dobs_from_text(psc_id,df)\n",
    "\n",
    "    # Formatting output\n",
    "    chips = op[0]\n",
    "    diff = op[1]\n",
    "    tag = op[2]\n",
    "    \n",
    "    tag_explained = tag.split(' - ')[0]\n",
    "    tag = tag.split(' - ')[1]\n",
    "    \n",
    "    if type(chips) == list:\n",
    "        chips = ', '.join(chips)\n",
    "        \n",
    "    if type(diff) == dict:\n",
    "        op_diff = ''\n",
    "        for key in diff.keys():\n",
    "            op_diff = op_diff + key + ': ' \n",
    "            op_diff = op_diff + ', '.join(diff[key]) + ' ' if len(diff[key]) > 0 else op_diff + 'None '\n",
    "        diff = op_diff\n",
    "    \n",
    "    df.loc[index,'CHIPS_value'] = chips\n",
    "    df.loc[index,'priority'] = tag\n",
    "    df.loc[index,'priority_explained'] = tag_explained\n",
    "    df.loc[index,'material_nonmaterial'] = 'MATERIAL' if 'NONE' not in op[2] else 'NON-MATERIAL'\n",
    "    \n",
    "    return diff "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3877b7ab",
   "metadata": {},
   "source": [
    "# OTHERS & PSC MISSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2fe6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the listed Discrepancies from the section\n",
    "def Discrepancy(x):\n",
    "    txt = re.search('Discrepancy Options:(\\s+)(.)*', x)\n",
    "    myText = txt.group(0).replace('Discrepancy Options:\\n ', '')\n",
    "    ls = myText.split(',')\n",
    "    return ls\n",
    "\n",
    "# find the material types of discrepancy within List of Discrepancies and assign Multi, Multi_NoNoc & Single\n",
    "def find_noc(x,optionList):\n",
    "    if len(x) > 1:\n",
    "        matching = [s for s in x if any(w in s for w in optionList)]\n",
    "        if matching:\n",
    "            return 'Multi'  # When material types of Discrepancies listed within Options\n",
    "        else:\n",
    "            return 'Multi-Low'  # Multiple discrepancy listed but only non-material types of discrepancy\n",
    "    else:\n",
    "        return 'Single'  # Only one types of discrepancy listed (material/non material)\n",
    " \n",
    "\n",
    "    \n",
    "# function to assign Material and Non-Material to discrepancies\n",
    "def material_nonmaterial(x):\n",
    "    # material types deiscrepancy\n",
    "    if x == 'Governing law' or x == 'Incorporation law' or x == 'Legal form' or x == 'Place of registration' or x == 'Place of residence' or x == 'Correspondence address' or x == 'Other reason' or x == 'Company number':\n",
    "        return 'MATERIAL'\n",
    "    # non-material types\n",
    "    elif x == 'Notified date' or x == 'Country of residence' :\n",
    "        return 'NON-MATERIAL'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "#  function to assign High/Low priority\n",
    "def priority(x):\n",
    "    # print(x)\n",
    "    # when option list contains any of high priority discrepancy\n",
    "    if x == 'Multi':\n",
    "        return 'HIGH'\n",
    "    # otherwise for the rest of discrepancy it will be low\n",
    "    else:\n",
    "        return 'LOW'\n",
    "    \n",
    "# function to find company number\n",
    "def compnum(x):\n",
    "    x = x.replace('\\n', ' ')\n",
    "    txt = re.search('Discrepancy Details:(.)*Discrepancy Options:', x)\n",
    "    cnum = re.search(r'\\d{5,12}', txt.group(0))\n",
    "    return cnum.group(0)\n",
    "\n",
    "# function to assign priority : compnay number df\n",
    "def compnum_priority(x):\n",
    "    if x['DISCREPANCY_COMPANY_NUMBER'] == x['text_difference']:\n",
    "        return 'Low'\n",
    "    else:\n",
    "        return 'High'\n",
    "    \n",
    "# find the different  types of discrepancy from the Other discrepancy while discrepancies are not listed clearly\n",
    "def othercontent(x):\n",
    "    x = x.lower().replace('\\n', ' ')\n",
    "    txt = re.search('discrepancy details:(.)*discrepancy options:', x)\n",
    "    mytext = txt.group(0)\n",
    "    # when person cesed or died\n",
    "    if 'ceased' in mytext or 'died' in mytext:\n",
    "        return 'Cease'\n",
    "    elif 'not a rle' in mytext or 'shouldn' in mytext or 'should not' in mytext or 'duplicat' in mytext or 'twice' in mytext or 'removed' in mytext or 'remove' in mytext or 'terminate' in mytext or 'not be listed' in mytext or 'should not be considered' in mytext or 'no ownership' in mytext or 'no longer' in mytext or 'not a psc' in mytext:\n",
    "        # print(mytext)\n",
    "        return 'PSC Remove'\n",
    "    # when PSC are still active/asked for update/to add the PSC\n",
    "    elif 'is still the active' in mytext or 'in addition' in mytext or 'still active' in mytext or 'added' in mytext or 'not updated' in mytext:\n",
    "        return 'PSC Add'\n",
    "    # when PSC complained about the missing VR\n",
    "    elif ('missing' in mytext or 'without' in mytext)  and 'voting rights' in mytext:\n",
    "        return 'Missing VR'\n",
    "    # when PSC asked for Share and Voting rights\n",
    "    elif '%' in mytext or 'share' in mytext or 'voting' in mytext or 'influence' in mytext or 'control' in mytext:\n",
    "        return 'Share & VR'\n",
    "    # when PSC asked for both addition and removal of PSC from the register\n",
    "    elif (\n",
    "             'not a rle' in mytext or 'shouldn' in mytext or 'should not' in mytext or 'duplicat' in mytext or 'twice' in mytext or 'removed' in mytext or 'remove' in mytext or 'terminate' in mytext or 'not be listed' in mytext or 'should not be considered' in mytext or 'no ownership' in mytext or 'no longer' in mytext or 'not a psc' in mytext)\\\n",
    "            and \\\n",
    "            ('is still the active' in mytext or 'added' in mytext or 'in addition' in mytext or 'still active' in mytext or 'not updated' in mytext):\n",
    "\n",
    "        return 'Both Addition and Removal'\n",
    "    # when PSC asked for both addition and removal of PSC from the register\n",
    "    elif 'is the psc and not' in mytext:\n",
    "        return 'Both Addition and Removal'\n",
    "    # when PSC are inactive/duplicate entry/ask for removal/termination of PSC\n",
    "    elif 'trust' in mytext: # about the trust\n",
    "        return 'Trust'\n",
    "    elif 'dob' in mytext: # when user talk about the DOB\n",
    "        return 'DOB'\n",
    "    elif 'incorrect' in mytext: # section describe incorrect details\n",
    "        return 'Incorrect details'\n",
    "    else:\n",
    "        return 'Miscellaneous'\n",
    "\n",
    "# mark in the Other reason discrepancy 'cease' as Non-Material and rest as Material\n",
    "def material(x):\n",
    "    # print(x)\n",
    "    if x == 'Cease':\n",
    "        return 'NON-MATERIAL'\n",
    "    else:\n",
    "        return 'MATERIAL'\n",
    "    \n",
    "def queother(x):\n",
    "    if (x['priority_explained'] == 'Missing VR'):\n",
    "        return 'LOW'\n",
    "    else:\n",
    "        return 'HIGH'\n",
    "    \n",
    "# assign the discrepancy to Other section based on text extracted from the above function\n",
    "def detailcontent(x):\n",
    "    x = x.replace('\\n', ' ')\n",
    "    txt = re.search('Discrepancy Details:(.)*Discrepancy Options:', x)\n",
    "    mytext = txt.group(0)\n",
    "    return mytext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fac7fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_cat_prio(df):\n",
    "\n",
    "    # Sub data frames :\n",
    "    dfglaws = df[df['PSC_DISCREPANCY_OPTION_DESC'] == 'Governing law'] # Governing Law dataframe\n",
    "    dfinlaw = df[df['PSC_DISCREPANCY_OPTION_DESC'] == 'Incorporation law'] # ncorporation law dataframe\n",
    "    dflegal = df[df['PSC_DISCREPANCY_OPTION_DESC'] == 'Legal form'] # Legal form dataframe\n",
    "    dfndate = df[df['PSC_DISCREPANCY_OPTION_DESC'] == 'Notified date'] # Notified date dataframe\n",
    "    dfcr = df[df['PSC_DISCREPANCY_OPTION_DESC'] == 'Country of residence'] # Country of residence dataframe\n",
    "    dfpr = df[df['PSC_DISCREPANCY_OPTION_DESC'] == 'Place of residence'] # lace of residence dataframe\n",
    "    dfpres = df[df['PSC_DISCREPANCY_OPTION_DESC'] == 'Place of registration'] # Place of registration dataframe\n",
    "    dfaddr = df[df['PSC_DISCREPANCY_OPTION_DESC'] == 'Correspondence address'] # Correspondence address dataframe\n",
    "    dfcomp = df[df['PSC_DISCREPANCY_OPTION_DESC'] == 'Company number'] # Company number dataframe\n",
    "    \n",
    "    df_frames = [dfglaws, dfinlaw, dflegal, dfndate, dfpr, dfpres,dfaddr,dfcomp] # for merging of the data frames\n",
    "    \n",
    "    df_result = pd.concat(df_frames) # concatenating dataframes\n",
    "    \n",
    "    #  Tag the whole data with Material/Non Material\n",
    "    df_result['material_nonmaterial'] = df_result['PSC_DISCREPANCY_OPTION_DESC'].apply(material_nonmaterial)\n",
    "    \n",
    "    #  assign priorities to whole df becoz these discrepancies would be either High: Multi or Low\n",
    "    df_result['priority'] = df_result['Discrepancy'].apply(priority)\n",
    "    \n",
    "    #  data frame for the 'Other reason'  discrepancy\n",
    "    dfother = df[df.PSC_DISCREPANCY_OPTION_DESC == 'Other reason']\n",
    "\n",
    "    # extract text from the other reason data frame\n",
    "    dfother['priority_explained'] = dfother['CONTACT_DETAIL_CLOB'].apply(othercontent)\n",
    "    dfother['material_nonmaterial'] = 'MATERIAL'\n",
    "    \n",
    "    dfother['priority'] = dfother.apply(queother,axis=1)\n",
    "    \n",
    "    # country of residence all to NONE\n",
    "    dfcr['materia_nonmaterial'] = 'NON-MATERIAL'\n",
    "    dfcr['priority'] = 'NONE'\n",
    "    dfcr['priority_explained'] = 'NON-MATERIAL PSC TYPE'\n",
    "    \n",
    "    frames = [df_result,dfother,dfcr]\n",
    "    \n",
    "    result = pd.concat(frames)\n",
    "    \n",
    "    #  Discrepancy detail section\n",
    "    result['discrepancy_detail'] = result['CONTACT_DETAIL_CLOB'].apply(detailcontent)\n",
    "    result['priority_explained'][result.priority_explained.isna()] = result[result.priority_explained.isna()].material_nonmaterial.apply(lambda x: 'NON-MATERIAL PSC TYPE' if x == 'NON-MATERIAL' else 'MATERIAL PSC TYPE')\n",
    "    result[df['PSC_DISCREPANCY_OPTION_DESC'] == 'Company number']['priority'] = 'HIGH'\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac33eac2",
   "metadata": {},
   "source": [
    "# PSC Missing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2651dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing(psc_id,df):\n",
    "    #if 'should be listed' or 'should be a psc' or 'no one listed' or 'should be on psc' or 'they should disclose' or 'is the psc' or 'the psc is' or 'the psc as' or 'psc register is empty' or '' \n",
    "    index = df[df.PSC_DISCREPANCY_ID == psc_id].index[0]\n",
    "    txt = df.loc[index,'discrepancy_detail']\n",
    "    cont_id = df.loc[index,'CONTACT_ID']\n",
    "    corp_id = df.loc[index,'CORPORATE_BODY_ID']\n",
    "    comp_name = df.loc[index,'SURNAME']\n",
    "    print(comp_name)\n",
    "    \n",
    "    # getting shareholder names\n",
    "    df_cont = df_off[df_off.CONTACT_ID == cont_id]\n",
    "    \n",
    "    if df_cont.shape[0] == 0:\n",
    "        return 'PSC Missing'\n",
    "    \n",
    "    sh_names = df_cont.merged_name.unique()\n",
    "    \n",
    "    sh_names = [name.lower() for name in sh_names]\n",
    "    sh_fores = [name.split(' ')[:-1] for name in sh_names]\n",
    "    \n",
    "    print(\"SH NAMES : \",sh_names)\n",
    "    sh_surs = [name.split(' ')[-1] for name in sh_names]\n",
    "    \n",
    "    pos_tags = get_pos_tags(txt,nlp,reduce_ents = False)\n",
    "    \n",
    "    \n",
    "    print(\"NAMES/ORGS IN TXT : \",[pos_tags['PERSON'],pos_tags['ORG']])\n",
    "\n",
    "    txt = txt.lower()\n",
    "    \n",
    "    surs_test = [sur for sur in sh_surs if sur in txt ]\n",
    "    names_test = [name for name in sh_names if name in txt]\n",
    "    print(\"SUR TEST \",surs_test)\n",
    "    print(\"NAME TEST \",names_test)\n",
    "    \n",
    "    if (len(surs_test)*len(names_test) == 0) and (len(pos_tags['PERSON']) == 0) and (len(pos_tags['ORG']) == 0):\n",
    "        return \"PSC Missing\"\n",
    "    \n",
    "    pos_tags['PERSON'] = [name for name in pos_tags['PERSON'] if name.lower() not in sh_names]\n",
    "    to_skip = ['psc','co','ltd','plc','ch','companies house'] \n",
    "    pos_tags['ORG'] = [name for name in pos_tags['ORG'] if (name.lower() != comp_name.lower()) and (name.lower() not in sh_names) and (name.lower() not in to_skip)]\n",
    "    \n",
    "    print(\"NAMES/ORGS IN TXT : \",[pos_tags['PERSON'],pos_tags['ORG']])\n",
    "\n",
    "    to_return = None\n",
    "    \n",
    "    if (len(surs_test) == 0) or (len(pos_tags['PERSON']) + len(pos_tags['ORG']) > 0):\n",
    "        to_return = 'PSC Missing'\n",
    "        \n",
    "    check_phrases = ['missing from psc','psc missing','should be psc','should be listed as psc','add psc','should have in psc tab','missing psc','missing as psc',\n",
    "                    'be listed as psc','be listed as a psc','no psc','missing as a psc','added as psc','should be on psc','noted as a psc','noted on psc','psc is missing',\n",
    "                    'should have in psc','add as PSC']\n",
    "    \n",
    "    phrases_test = [True if phrase in txt else False for phrase in check_phrases]\n",
    "    \n",
    "    if any(phrases_test) == True:\n",
    "        to_return = 'PSC Missing'\n",
    "    \n",
    "    if ('missing' in txt or 'should be' in txt) and ('psc' in txt):\n",
    "        to_return = 'PSC Missing'\n",
    "\n",
    "    if to_return == 'PSC Missing' and len(pos_tags['PERSON']) + len(pos_tags['ORG']) == 0 and len(names_test) > 0 :\n",
    "        to_return = 'Missing PSC Found'\n",
    "        \n",
    "    return to_return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf4ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_prio(psc_id,df):\n",
    "    op = check_missing(psc_id,df)\n",
    "    index = df[df.PSC_DISCREPANCY_ID == psc_id].index[0]\n",
    "\n",
    "    if op == None:\n",
    "        op = othercontent(df.loc[index,'CONTACT_DETAIL_CLOB'])\n",
    "    \n",
    "    if (op == 'Missing VR') and (df.loc[index,'PSC_DISCREPANCY_OPTION_DESC'] != 'Nature of Control'):\n",
    "        df.loc[index,'material_nonmaterial'] = 'MATERIAL'\n",
    "        df.loc[index,'priority'] = 'LOW'\n",
    "    elif op == 'Missing PSC Found':\n",
    "        df.loc[index,'material_nonmaterial'] = 'NON-MATERIAL'\n",
    "        df.loc[index,'priority'] = 'NONE'\n",
    "    else:\n",
    "        if df.loc[index,'PSC_DISCREPANCY_OPTION_DESC'] != 'Nature of Control':\n",
    "            df.loc[index,'material_nonmaterial'] = 'MATERIAL'\n",
    "            df.loc[index,'priority'] = 'HIGH'\n",
    "        else:\n",
    "            op = df.loc[index,'priority_explained']\n",
    "    \n",
    "    return op # priority_explained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd03b19a",
   "metadata": {},
   "source": [
    "# Bringing it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efdb235",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def run_report(df):\n",
    "    # preprocessing...\n",
    "    print(\"Preprocessing\") \n",
    "    print(\"BEFORE ACT CODE & DEDUP : \",df.shape)\n",
    "    df = preprocess_df(df)\n",
    "    df['act_code_flag'] = df['CONTACT_ID'].apply(lambda x :check_act(x,df_act))\n",
    "\n",
    "    \n",
    "    df = df[df['act_code_flag'] != True]\n",
    "    print(\"AFTER ACT CODE & DEDUP : \",df.shape)\n",
    "    \n",
    "    \n",
    "    start_inds = list(df.PSC_DISCREPANCY_ID.unique())\n",
    "    \n",
    "    #  Types of Discrepancy (Single/Multi-NoNOC/Multi) for whole data set\n",
    "    optionList = ['Nature of control', 'Date of birth','Name','Company number','Company name'] # Material type of Major Discreapancy (High priority)\n",
    "    #  List all the discrepancies\n",
    "    df['Discrepancy'] = df['option_descrip_all'].apply(lambda x: find_noc(x,optionList))\n",
    "    \n",
    "    print(\"DONE\\n\")\n",
    "    \n",
    "    # Extraction and comparison\n",
    "    df['CHIPS_value'] = None\n",
    "    df['text_difference'] = None\n",
    "    df['priority_explained'] = None\n",
    "    df['priority'] = None\n",
    "    df['material_nonmaterial'] = None\n",
    "    \n",
    "    dfname = df[(df.PSC_DISCREPANCY_OPTION_DESC == 'Name') & (df.Discrepancy == 'Single')]\n",
    "    dfnoc = df[(df.PSC_DISCREPANCY_OPTION_DESC == 'Nature of control') & (df.Discrepancy == 'Single')]\n",
    "    dfdob = df[(df.PSC_DISCREPANCY_OPTION_DESC == 'Date of birth') & (df.Discrepancy == 'Single')]\n",
    "    dfnat = df[(df.PSC_DISCREPANCY_OPTION_DESC == 'Nationality') & (df.Discrepancy == 'Single')]\n",
    "    dfcname = df[(df.PSC_DISCREPANCY_OPTION_DESC == 'Company name') & (df.Discrepancy == 'Single')]\n",
    "    \n",
    "    dfname['text_difference'] = dfname.PSC_DISCREPANCY_ID.apply(lambda x: name_prio(x,dfname))\n",
    "    print(\"NAME DONE\")\n",
    "    dfnoc['text_difference'] = dfnoc.PSC_DISCREPANCY_ID.apply(lambda x: noc_prio(x,dfnoc))\n",
    "    print(\"NOC DONE\")\n",
    "    dfdob['text_difference'] = dfdob.PSC_DISCREPANCY_ID.apply(lambda x: dob_prio(x,dfdob))\n",
    "    print(\"DOB DONE\")\n",
    "    dfnat['text_difference'] = dfnat.PSC_DISCREPANCY_ID.apply(lambda x: nationality_prio(x,dfnat))\n",
    "    print(\"NAT DONE\")\n",
    "    \n",
    "    dfcname['priority'] = 'HIGH'\n",
    "    dfcname['material_nonmaterial'] = 'MATERIAL'\n",
    "    dfcname['priority_explained'] = 'MATERIAL PSC TYPE'\n",
    "    \n",
    "    \n",
    "    dfmulti = df[df.Discrepancy != 'Single']\n",
    "    dfmulti['priority'] = [tag_multiple(x) for x in dfmulti.option_descrip_all.values]\n",
    "    dfmulti['material_nonmaterial'] = dfmulti['priority'].apply(lambda x: 'MATERIAL' if x != None else 'NON-MATERIAL')\n",
    "    print(\"MULTI DONE\")\n",
    "    \n",
    "    # dealing with PSC Missing\n",
    "    df_miss = df[(df.PSC_DISCREPANCY_TYPE_DESC == 'PSC Missing') & (df.Discrepancy == 'Single')]\n",
    "    print(\"\\n================\\n\",df_miss.shape)\n",
    "    df_miss['priority_explained'] = df_miss.PSC_DISCREPANCY_ID.apply(lambda x: missing_prio(x,df_miss))\n",
    "    \n",
    "    df_rest = other_cat_prio(df[df.Discrepancy == 'Single'])\n",
    "    print(\"OTHERS DONE\")\n",
    "    \n",
    "    frames = [dfname,dfnoc,dfdob,dfnat,dfmulti,dfcname,df_rest,df_miss]\n",
    "    df_op = pd.concat(frames)\n",
    "                                                                     \n",
    "    df_op[(df_op.PSC_DISCREPANCY_OPTION_DESC == 'Nature of control') & (df_op.priority == 'NONE')]['priority_explained'] = df_op[(df_op.PSC_DISCREPANCY_OPTION_DESC == 'Nature of control') & (df_op.priority == 'NONE')].PSC_DISCREPANCY_ID.apply(lambda x: missing_prio(x,df_op))\n",
    "    \n",
    "    for ind in df_op[df_op.priority_explained == 'Share & VR'].index:                                                                     \n",
    "        psc_id = df_op.loc[ind,'PSC_DISCREPANCY_ID']\n",
    "        try:\n",
    "            txt_diff = noc_prio(psc_id,df_op)\n",
    "            df_op.loc[ind,'text_difference'] = txt_diff\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    return df_op\n",
    "\n",
    "df_op = run_report(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bd140a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "col_sel = ['CREATED_DATE','COMPANY_NUMBER','PSC_DISCREPANCY_ID','CORPORATE_BODY_ID','PSC_DISCREPANCY_TYPE_DESC','PSC_DISCREPANCY_OPTION_DESC','discrepancy_detail','Discrepancy',\n",
    "                    'option_descrip_all','CHIPS_value','text_difference','priority_explained',\n",
    "                    'priority','material_nonmaterial']\n",
    "\n",
    "df_for_team = df_op[col_sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d0c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_team = df_for_team.sort_values(by='CREATED_DATE')\n",
    "#df_for_team.to_csv('FINAL REPORT WEBSERVICES 11.10.csv',index = False)\n",
    "df_for_team.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee167d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_team.to_csv('OUTPUT.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
